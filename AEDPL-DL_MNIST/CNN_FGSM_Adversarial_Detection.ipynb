{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\art\\estimators\\certification\\__init__.py:28: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import CNN # External class generated for CNN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "epochs=100\n",
    "batch_size=250\n",
    "\n",
    "\n",
    "eps_FSGM=0.10\n",
    "\n",
    "# Select the attacker\n",
    "#White-box: \"FGSM\", \"BIM\", \"PGD\", \n",
    "#Black-box: \"SA\",\"ZA\"\n",
    "attack_type = \"FGSM\"\n",
    "dataset=\"MNIST\"   # MNIST, CIRFAR10\n",
    "\n",
    "#path='results/MNIST_BA.txt' #this for MNIST images\n",
    "path='C:/Users/02729/OneDrive - Universiti Teknikal Malaysia Melaka/Desktop/IEEE Access paper/MNIST/results1/MNIST/MNIST_FGSM.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.3826 - accuracy: 0.8769\n",
      "Done...Time consumed in training: 18.43698024749756\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "from art.utils import load_mnist\n",
    "(train_images, train_labels), (test_images, test_labels), min_pixel_value, max_pixel_value = load_mnist()\n",
    "train_images, test_images = train_images / max_pixel_value, test_images / max_pixel_value\n",
    "\n",
    "\n",
    "'''# Load CIFAR-10 dataset\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "min_pixel_value = 0.0\n",
    "max_pixel_value = 1.0'''\n",
    "\n",
    "\n",
    "\n",
    "classifier, t_consumed = CNN.train(train_images, train_labels, epochs, batch_size,\n",
    "                                   min_pixel_value, max_pixel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 97.72 97.75 97.72 97.72\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "acc, prc, rec, f1 = CNN.test(classifier, test_images, test_labels)\n",
    "\n",
    "#write the results\n",
    "import Writer\n",
    "results =\"===========\\n\" +  dataset + \"-Regular:\\n acc, prc, rec, f1, epochs, batch size, time: acc, prc, rec, f1\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(epochs)+ \",\" + str(batch_size) + \",\" + str(int(t_consumed)) +\"\\n\" \n",
    "Writer.write_results(results, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features for the regular images\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_2').output)\n",
    "Features_regular = model_output.predict(test_images)\n",
    "print(Features_regular.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial examples using the FastGradientMethod attack\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent #white-box\n",
    "from art.attacks.evasion import ZooAttack, SquareAttack, BoundaryAttack #black-box\n",
    "\n",
    "\n",
    "# Initialize the attack\n",
    "attack = None\n",
    "\n",
    "# Select the attack\n",
    "if attack_type == \"FGSM\":\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "if attack_type == \"BIM\":\n",
    "    attack = BasicIterativeMethod(estimator=classifier, eps=eps_FSGM)\n",
    "elif attack_type == \"PGD\":\n",
    "    attack = ProjectedGradientDescent(estimator=classifier, eps=eps_FSGM)\n",
    "elif attack_type == \"SA\":\n",
    "    attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "elif attack_type == \"ZA\":\n",
    "    attack = ZooAttack(classifier=classifier, max_iter=2, learning_rate=eps_FSGM)\n",
    "\n",
    "\n",
    "\n",
    "adv_images = attack.generate(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.02 84.6 84.02 84.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the adversarial test set images\n",
    "acc, prc, rec, f1 = CNN.test(classifier, adv_images, test_labels)\n",
    "\n",
    "#write the results\n",
    "results =dataset + \"-Adversarial:\\n acc, prc, rec, f1, epochs, attack_type, eps_FSGM\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + attack_type + \",\" + str(eps_FSGM) +\"\\n\" \n",
    "Writer.write_results(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features for the adversarial images\n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_2').output)\n",
    "Features_adversarial = model_output.predict(adv_images)\n",
    "print(Features_adversarial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "# merge regular and feature test images\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#merge data features of regular and adversarial images\n",
    "reg_adv_images = np.concatenate((Features_regular, Features_adversarial), axis=0)\n",
    "\n",
    "# generate labels for regular and adversarial, and merge them\n",
    "\n",
    "label_reg = np.zeros((10000, 1))\n",
    "label_adv = np.ones((10000, 1))\n",
    "reg_adv_labels=np.concatenate((label_reg, label_adv), axis=0)\n",
    "\n",
    "print(\"data details: \", reg_adv_images.shape, \" , labels: \", reg_adv_labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reg_adv_images, reg_adv_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "#fractin to use a part of the merged regular and adversarial images\n",
    "fraction=1\n",
    "#reduce the length because the memory is out\n",
    "X_train=X_train[:int(X_train.shape[0]/fraction)]\n",
    "X_test=X_test[:(int(X_test.shape[0]/fraction))]\n",
    "y_train=y_train[:(int(y_train.shape[0]/fraction))]\n",
    "y_test=y_test[:(int(y_test.shape[0]/fraction))]\n",
    "X_train, X_test, y_train, y_test\n",
    "print(\"data after split : X_train, X_test, y_train, y_test\\n\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import ML_Classifiers as MLC\\n\\nRF_Pred= MLC.Random_Forest(X_train, X_test, y_train, y_test)\\nDT_Pred= MLC.DT(X_train, X_test, y_train, y_test)\\nKNN_Pred= MLC.KNN(X_train, X_test, y_train, y_test)\\nXGB_Pred= MLC.XGB(X_train, X_test, y_train, y_test)\\nNN_Pred= MLC.NN(X_train, X_test, y_train, y_test)\\nNN_Pred= MLC.GBM(X_train, X_test, y_train, y_test)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import ML_Classifiers as MLC\n",
    "\n",
    "RF_Pred= MLC.Random_Forest(X_train, X_test, y_train, y_test)\n",
    "DT_Pred= MLC.DT(X_train, X_test, y_train, y_test)\n",
    "KNN_Pred= MLC.KNN(X_train, X_test, y_train, y_test)\n",
    "XGB_Pred= MLC.XGB(X_train, X_test, y_train, y_test)\n",
    "NN_Pred= MLC.NN(X_train, X_test, y_train, y_test)\n",
    "NN_Pred= MLC.GBM(X_train, X_test, y_train, y_test)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28, 1) (20000, 10)\n",
      "acc, prc, rec, f1: 90.87 91.11 90.87 90.87\n"
     ]
    }
   ],
   "source": [
    "# integrate the adversarial detector model to CNN to exclude adversarial images or outlier images.\n",
    "\n",
    "size_advs=10000\n",
    "test_reg_adv_images=np.concatenate((test_images,adv_images[:size_advs]), axis=0)\n",
    "test_reg_adv_labels=np.concatenate((test_labels,test_labels[:size_advs]), axis=0)\n",
    "print(test_reg_adv_images.shape, test_reg_adv_labels.shape)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(len(test_reg_adv_images))\n",
    "np.random.shuffle(indices)\n",
    "test_reg_adv_images= test_reg_adv_images[indices]\n",
    "test_reg_adv_labels = test_reg_adv_labels[indices]\n",
    "\n",
    "# Evaluate the model after integrate regular and adversarial images\n",
    "acc, prc, rec, f1 = CNN.test(classifier, test_reg_adv_images, test_reg_adv_labels)\n",
    "results =dataset + \"-Regular+Adversarial:\\n acc, prc, rec, f1\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) +\"\\n\" \n",
    "Writer.write_results(results, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract features \n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_2').output)\n",
    "Features_adv_reg = model_output.predict(test_reg_adv_images)\n",
    "print(Features_adversarial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ensure that the size of regular and adversarial image size are the same to do fair evaluation\n",
    "def make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels):\n",
    "    diff=int(np.absolute(clean_images.shape[0] - attacked_images.shape[0])/2)\n",
    "    size=int((clean_images.shape[0]+attacked_images.shape[0])/2)\n",
    "    temp_clean_images=np.ones((size,28,28,1))\n",
    "    temp_attacked_images=np.ones((size,28,28,1))\n",
    "\n",
    "    temp_clean_labels=np.ones((size,10))\n",
    "    temp_attacked_labels=np.ones((size,10))\n",
    "    \n",
    "    if(clean_images.shape[0]>attacked_images.shape[0]):\n",
    "        temp_clean_images=clean_images[:size]\n",
    "        temp_clean_labels=clean_labels[:size]\n",
    "        \n",
    "        temp_attacked_images=np.concatenate((attacked_images,clean_images[-diff:]), axis=0)\n",
    "        temp_attacked_labels=np.concatenate((temp_attacked_labels,clean_labels[-diff:]), axis=0)\n",
    "        \n",
    "    elif(clean_images.shape[0]<attacked_images.shape[0]):\n",
    "        temp_attacked_images=attacked_images[:size]\n",
    "        temp_attacked_labels=attacked_labels[:size]\n",
    "\n",
    "        temp_clean_images=np.concatenate((clean_images,attacked_images[-diff:]), axis=0)\n",
    "        temp_clean_labels=np.concatenate((clean_labels,attacked_labels[-diff:]), axis=0)\n",
    "\n",
    "    clean_images=temp_clean_images\n",
    "    clean_labels=temp_clean_labels\n",
    "    \n",
    "    attacked_images=temp_attacked_images\n",
    "    attacked_labels=temp_attacked_labels\n",
    "    \n",
    "    #print(\"clean_images.shape, attacked_images.shape\", clean_images.shape, attacked_images.shape)\n",
    "    #print(\"clean_labels.shape, attacked_labels.shape\", clean_labels.shape, attacked_labels.shape)\n",
    "    \n",
    "    return clean_images,clean_labels, attacked_images, attacked_labels\n",
    "\n",
    "#Exclude adversarial images from testing and use only the regular images\n",
    "\n",
    "def retrurn_clean_images(adv_images_pred_binary):\n",
    "    \n",
    "    # Count the number of times 1 appears in the array\n",
    "    number_of_1s = np.count_nonzero(adv_images_pred_binary == 1)\n",
    "    # Count the number of times 0 appears in the array\n",
    "    number_of_0s = np.count_nonzero(adv_images_pred_binary == 0)\n",
    "    print(\"The number of attacked immages 1 is:\", number_of_1s)\n",
    "    print(\"The number of clean images 0 is:\", number_of_0s)\n",
    "\n",
    "    #Exclude adversarial images from testing and use only the regular images\n",
    "    # Create a boolean mask use only the clean images\n",
    "    mask_clean = np.where(adv_images_pred_binary == 0)[0]\n",
    "    mask_adv = np.where(adv_images_pred_binary == 1)[0]\n",
    "\n",
    "    # Exclude adversarial images\n",
    "    #clean images\n",
    "    clean_images = test_reg_adv_images[mask_clean]\n",
    "    clean_labels = test_reg_adv_labels[mask_clean]\n",
    "    #Adversarial images,attacked images\n",
    "    attacked_images = test_reg_adv_images[mask_adv]\n",
    "    attacked_labels = test_reg_adv_labels[mask_adv]\n",
    "    \n",
    "    clean_images,clean_labels, attacked_images, attacked_labels = make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels)\n",
    "    \n",
    "    print(\"clean_images:\", clean_images.shape)\n",
    "    print(\"clean_labels:\", clean_labels.shape)\n",
    "    \n",
    "    return clean_images, clean_labels\n",
    "\n",
    "\n",
    "def eval_model_after_exclude_adv_image(model_name, new_test_clean_images, new_test_clean_labels, t_consumed):# Evaluate the model after excluding the adversarial images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, new_test_clean_images, new_test_clean_labels)\n",
    "    results =model_name + \":\\n acc, prc, rec, f1, time_detection\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(int(t_consumed)) + \"\\n\" \n",
    "    Writer.write_results(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 1s 34us/sample - loss: 0.6419 - accuracy: 0.6432\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 1s 33us/sample - loss: 0.5318 - accuracy: 0.7378\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.4847 - accuracy: 0.7726\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.4578 - accuracy: 0.7847\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.4367 - accuracy: 0.7951\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 1s 33us/sample - loss: 0.4204 - accuracy: 0.8054\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.4045 - accuracy: 0.8195\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.3960 - accuracy: 0.8222\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.3842 - accuracy: 0.8273\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.3736 - accuracy: 0.8321\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.3680 - accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.3645 - accuracy: 0.8382\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.3638 - accuracy: 0.8396\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.3589 - accuracy: 0.8384\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.3464 - accuracy: 0.8498\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.3445 - accuracy: 0.8484\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 1s 35us/sample - loss: 0.3422 - accuracy: 0.8472\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 1s 37us/sample - loss: 0.3361 - accuracy: 0.8556\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.3365 - accuracy: 0.8510\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.3271 - accuracy: 0.8559\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 1s 35us/sample - loss: 0.3295 - accuracy: 0.8553\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.3277 - accuracy: 0.8580\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.3218 - accuracy: 0.8568\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.3183 - accuracy: 0.8597\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 1s 34us/sample - loss: 0.3177 - accuracy: 0.8616\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.3135 - accuracy: 0.8631\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 1s 32us/sample - loss: 0.3093 - accuracy: 0.8658\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 1s 32us/sample - loss: 0.3160 - accuracy: 0.8629\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 1s 34us/sample - loss: 0.3116 - accuracy: 0.8641\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 1s 40us/sample - loss: 0.3033 - accuracy: 0.8668\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.3081 - accuracy: 0.8657\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.3070 - accuracy: 0.8658\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.3008 - accuracy: 0.8708\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2998 - accuracy: 0.8687\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.2996 - accuracy: 0.8695\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.2944 - accuracy: 0.8730\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2945 - accuracy: 0.8719\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.2963 - accuracy: 0.8725\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2908 - accuracy: 0.8729\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 1s 36us/sample - loss: 0.2911 - accuracy: 0.8716\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2897 - accuracy: 0.8751\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.2867 - accuracy: 0.8760\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.2884 - accuracy: 0.8759\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 1s 37us/sample - loss: 0.2805 - accuracy: 0.8813\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2835 - accuracy: 0.8809\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2828 - accuracy: 0.8796\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2789 - accuracy: 0.8806\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.2794 - accuracy: 0.8799\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 1s 33us/sample - loss: 0.2799 - accuracy: 0.8773\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2772 - accuracy: 0.8808\n",
      "NN detection: acc, prc, rec, f1: 86.28 86.31 86.28 86.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:251: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 10426\n",
      "The number of clean images 0 is: 9574\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n",
      "acc, prc, rec, f1: 97.51 97.52 97.51 97.51\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the mosdel after inegrate NN as outlier detection to exclude Adversarial images\n",
    "import ML_Classifiers as MLC\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.NN(X_train, X_test, y_train, y_test,eps_FSGM, attack_type, Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+NN_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 84.52 84.98 84.52 84.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:38: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 10225\n",
      "The number of clean images 0 is: 9775\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n",
      "acc, prc, rec, f1: 97.57 97.6 97.57 97.57\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate RF as outlier detection to exclude Adversarial images\n",
    "import ML_Classifiers as MLC\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.Random_Forest(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+RF_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT detection: acc, prc, rec, f1: 74.3 74.3 74.3 74.3\n",
      "The number of attacked immages 1 is: 9986\n",
      "The number of clean images 0 is: 10014\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:113: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 97.08 97.13 97.08 97.08\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate DT as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "adv_images_pred_binary= MLC.DT(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+DT_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 79.2 79.85 79.2 79.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:74: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 11252\n",
      "The number of clean images 0 is: 8748\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n",
      "acc, prc, rec, f1: 96.85 96.9 96.85 96.85\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate KNN as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "adv_images_pred_binary= MLC.KNN(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+KNN_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 78.08 78.69 78.08 77.98\n",
      "The number of attacked immages 1 is: 11435\n",
      "The number of clean images 0 is: 8565\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 96.1 96.15 96.1 96.1\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate GBM as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.GBM(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+GBM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB detection: acc, prc, rec, f1: 69.05 69.91 69.05 68.76\n",
      "The number of attacked immages 1 is: 11986\n",
      "The number of clean images 0 is: 8014\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\ML_Classifiers.py:160: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 94.64 94.75 94.64 94.64\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate XGB as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.XGB(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+XGB_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378  values were replaced from  1000\n",
      "FAM detection: acc, prc, rec, f1: 60.7 58.14 70.14 63.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02729\\OneDrive - Universiti Teknikal Malaysia Melaka\\Desktop\\IEEE Access paper\\MNIST\\FAM.py:71: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 1, 'ArtB': [1.0, 0.0], 'id': '1000'}\n",
      "The number of attacked immages 1 is: 11542\n",
      "The number of clean images 0 is: 8458\n",
      "clean_images: (10000, 28, 28, 1)\n",
      "clean_labels: (10000, 10)\n",
      "acc, prc, rec, f1: 92.26 92.39 92.26 92.25\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate FAM as outlier detection to exclude Adversarial images\n",
    "import FAM \n",
    "\n",
    "t_str=time.time()\n",
    "ArtMap=FAM.train(X_train[:5000], y_train[:5000])\n",
    "\n",
    "adv_images_pred_binary = FAM.test(X_test[:1000], y_test[:1000], ArtMap, Features_adv_reg)\n",
    "\n",
    "adv_images_pred_binary=np.array(adv_images_pred_binary)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+FAM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from art.attacks.evasion import ZooAttack\n",
    "attack = ZooAttack(classifier=classifier)\n",
    "\n",
    "\n",
    "\n",
    "#attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "adv_images = attack.generate(test_images)\n",
    "\n",
    "attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "adv_images = attack.generate(test_images)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
