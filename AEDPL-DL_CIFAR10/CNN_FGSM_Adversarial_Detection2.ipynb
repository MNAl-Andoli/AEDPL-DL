{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import CNN # External class generated for CNN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "epochs=100\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "eps_FSGM=0.10\n",
    "\n",
    "# Select the attacker\n",
    "#White-box: \"FGSM\", \"BIM\", \"PGD\", \n",
    "#Black-box: \"SA\",\"ZA\"\n",
    "attack_type = \"SA\"\n",
    "dataset=\"CIRFAR10\"   # MNIST, CIRFAR10\n",
    "\n",
    "#path='results/MNIST_BA.txt' #this for MNIST images\n",
    "path='results/CIRFAR10/CIRFAR10_SA.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/app/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/75\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.7113 - accuracy: 0.3702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 1.7113 - accuracy: 0.3702 - val_loss: 2.5522 - val_accuracy: 0.2284\n",
      "Epoch 2/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 1.2303 - accuracy: 0.5645 - val_loss: 1.1015 - val_accuracy: 0.6148\n",
      "Epoch 3/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 1.0090 - accuracy: 0.6525 - val_loss: 1.0406 - val_accuracy: 0.6439\n",
      "Epoch 4/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.8685 - accuracy: 0.7044 - val_loss: 0.7623 - val_accuracy: 0.7405\n",
      "Epoch 5/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.7732 - accuracy: 0.7396 - val_loss: 0.8069 - val_accuracy: 0.7263\n",
      "Epoch 6/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.6924 - accuracy: 0.7693 - val_loss: 0.6370 - val_accuracy: 0.7841\n",
      "Epoch 7/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.6339 - accuracy: 0.7905 - val_loss: 0.6984 - val_accuracy: 0.7653\n",
      "Epoch 8/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.5795 - accuracy: 0.8088 - val_loss: 0.6168 - val_accuracy: 0.7985\n",
      "Epoch 9/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.5410 - accuracy: 0.8214 - val_loss: 0.6307 - val_accuracy: 0.7992\n",
      "Epoch 10/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.4969 - accuracy: 0.8366 - val_loss: 0.5906 - val_accuracy: 0.8128\n",
      "Epoch 11/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.4709 - accuracy: 0.8434 - val_loss: 0.5700 - val_accuracy: 0.8192\n",
      "Epoch 12/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.4346 - accuracy: 0.8563 - val_loss: 0.6420 - val_accuracy: 0.7986\n",
      "Epoch 13/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.4076 - accuracy: 0.8661 - val_loss: 0.5566 - val_accuracy: 0.8277\n",
      "Epoch 14/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.3824 - accuracy: 0.8735 - val_loss: 0.5472 - val_accuracy: 0.8327\n",
      "Epoch 15/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.3641 - accuracy: 0.8792 - val_loss: 0.5277 - val_accuracy: 0.8368\n",
      "Epoch 16/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.3428 - accuracy: 0.8872 - val_loss: 0.5815 - val_accuracy: 0.8286\n",
      "Epoch 17/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.3268 - accuracy: 0.8910 - val_loss: 0.6193 - val_accuracy: 0.8242\n",
      "Epoch 18/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.3114 - accuracy: 0.8958 - val_loss: 0.5481 - val_accuracy: 0.8379\n",
      "Epoch 19/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2874 - accuracy: 0.9053 - val_loss: 0.6234 - val_accuracy: 0.8262\n",
      "Epoch 20/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2813 - accuracy: 0.9074 - val_loss: 0.6119 - val_accuracy: 0.8277\n",
      "Epoch 21/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2634 - accuracy: 0.9109 - val_loss: 0.6199 - val_accuracy: 0.8244\n",
      "Epoch 22/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2518 - accuracy: 0.9153 - val_loss: 0.5616 - val_accuracy: 0.8414\n",
      "Epoch 23/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2396 - accuracy: 0.9211 - val_loss: 0.6078 - val_accuracy: 0.8393\n",
      "Epoch 24/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2303 - accuracy: 0.9217 - val_loss: 0.5983 - val_accuracy: 0.8379\n",
      "Epoch 25/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2166 - accuracy: 0.9278 - val_loss: 0.5728 - val_accuracy: 0.8411\n",
      "Epoch 26/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2139 - accuracy: 0.9290 - val_loss: 0.6258 - val_accuracy: 0.8355\n",
      "Epoch 27/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.2098 - accuracy: 0.9308 - val_loss: 0.6481 - val_accuracy: 0.8263\n",
      "Epoch 28/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1976 - accuracy: 0.9332 - val_loss: 0.6725 - val_accuracy: 0.8292\n",
      "Epoch 29/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1833 - accuracy: 0.9385 - val_loss: 0.6296 - val_accuracy: 0.8419\n",
      "Epoch 30/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1841 - accuracy: 0.9396 - val_loss: 0.6348 - val_accuracy: 0.8339\n",
      "Epoch 31/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1811 - accuracy: 0.9394 - val_loss: 0.6108 - val_accuracy: 0.8434\n",
      "Epoch 32/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1716 - accuracy: 0.9435 - val_loss: 0.7233 - val_accuracy: 0.8288\n",
      "Epoch 33/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1651 - accuracy: 0.9451 - val_loss: 0.6545 - val_accuracy: 0.8442\n",
      "Epoch 34/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1592 - accuracy: 0.9470 - val_loss: 0.6382 - val_accuracy: 0.8425\n",
      "Epoch 35/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1521 - accuracy: 0.9499 - val_loss: 0.6771 - val_accuracy: 0.8418\n",
      "Epoch 36/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1535 - accuracy: 0.9492 - val_loss: 0.6607 - val_accuracy: 0.8468\n",
      "Epoch 37/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1467 - accuracy: 0.9525 - val_loss: 0.6537 - val_accuracy: 0.8445\n",
      "Epoch 38/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1418 - accuracy: 0.9534 - val_loss: 0.6443 - val_accuracy: 0.8478\n",
      "Epoch 39/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1379 - accuracy: 0.9543 - val_loss: 0.6930 - val_accuracy: 0.8441\n",
      "Epoch 40/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1370 - accuracy: 0.9553 - val_loss: 0.7656 - val_accuracy: 0.8243\n",
      "Epoch 41/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1297 - accuracy: 0.9572 - val_loss: 0.7197 - val_accuracy: 0.8482\n",
      "Epoch 42/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1264 - accuracy: 0.9586 - val_loss: 0.7350 - val_accuracy: 0.8398\n",
      "Epoch 43/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1320 - accuracy: 0.9566 - val_loss: 0.6915 - val_accuracy: 0.8421\n",
      "Epoch 44/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1228 - accuracy: 0.9597 - val_loss: 0.7054 - val_accuracy: 0.8496\n",
      "Epoch 45/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1154 - accuracy: 0.9618 - val_loss: 0.7367 - val_accuracy: 0.8468\n",
      "Epoch 46/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1183 - accuracy: 0.9615 - val_loss: 0.6628 - val_accuracy: 0.8519\n",
      "Epoch 47/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1123 - accuracy: 0.9634 - val_loss: 0.7009 - val_accuracy: 0.8484\n",
      "Epoch 48/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1147 - accuracy: 0.9627 - val_loss: 0.7205 - val_accuracy: 0.8469\n",
      "Epoch 49/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1126 - accuracy: 0.9630 - val_loss: 0.7085 - val_accuracy: 0.8477\n",
      "Epoch 50/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1103 - accuracy: 0.9636 - val_loss: 0.6920 - val_accuracy: 0.8491\n",
      "Epoch 51/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1039 - accuracy: 0.9657 - val_loss: 0.7945 - val_accuracy: 0.8458\n",
      "Epoch 52/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1075 - accuracy: 0.9652 - val_loss: 0.6741 - val_accuracy: 0.8480\n",
      "Epoch 53/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1045 - accuracy: 0.9657 - val_loss: 0.7048 - val_accuracy: 0.8530\n",
      "Epoch 54/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1026 - accuracy: 0.9673 - val_loss: 0.7517 - val_accuracy: 0.8455\n",
      "Epoch 55/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1061 - accuracy: 0.9653 - val_loss: 0.6996 - val_accuracy: 0.8492\n",
      "Epoch 56/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0960 - accuracy: 0.9684 - val_loss: 0.8500 - val_accuracy: 0.8259\n",
      "Epoch 57/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0953 - accuracy: 0.9687 - val_loss: 0.7817 - val_accuracy: 0.8404\n",
      "Epoch 58/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0924 - accuracy: 0.9706 - val_loss: 0.7606 - val_accuracy: 0.8484\n",
      "Epoch 59/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0933 - accuracy: 0.9704 - val_loss: 0.7878 - val_accuracy: 0.8503\n",
      "Epoch 60/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0898 - accuracy: 0.9717 - val_loss: 0.7379 - val_accuracy: 0.8537\n",
      "Epoch 61/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0902 - accuracy: 0.9710 - val_loss: 0.7958 - val_accuracy: 0.8408\n",
      "Epoch 62/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0867 - accuracy: 0.9718 - val_loss: 0.8055 - val_accuracy: 0.8418\n",
      "Epoch 63/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0923 - accuracy: 0.9704 - val_loss: 0.7342 - val_accuracy: 0.8496\n",
      "Epoch 64/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0877 - accuracy: 0.9713 - val_loss: 0.7533 - val_accuracy: 0.8469\n",
      "Epoch 65/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0889 - accuracy: 0.9704 - val_loss: 0.7909 - val_accuracy: 0.8493\n",
      "Epoch 66/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0881 - accuracy: 0.9716 - val_loss: 0.7916 - val_accuracy: 0.8450\n",
      "Epoch 67/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0824 - accuracy: 0.9744 - val_loss: 0.7374 - val_accuracy: 0.8530\n",
      "Epoch 68/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0868 - accuracy: 0.9730 - val_loss: 0.7149 - val_accuracy: 0.8538\n",
      "Epoch 69/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0776 - accuracy: 0.9749 - val_loss: 0.7785 - val_accuracy: 0.8572\n",
      "Epoch 70/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0780 - accuracy: 0.9748 - val_loss: 0.7900 - val_accuracy: 0.8482\n",
      "Epoch 71/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0791 - accuracy: 0.9738 - val_loss: 0.7534 - val_accuracy: 0.8530\n",
      "Epoch 72/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0808 - accuracy: 0.9741 - val_loss: 0.7859 - val_accuracy: 0.8505\n",
      "Epoch 73/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0804 - accuracy: 0.9742 - val_loss: 0.7838 - val_accuracy: 0.8495\n",
      "Epoch 74/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0787 - accuracy: 0.9754 - val_loss: 0.7415 - val_accuracy: 0.8475\n",
      "Epoch 75/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0781 - accuracy: 0.9742 - val_loss: 0.7467 - val_accuracy: 0.8531\n",
      "Done...Time consumed in training: 8182.035628080368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Save the model\\nclassifier.save(\"/home/app/Desktop/paper 6/code_CIFAR10/classifier.h5\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "min_pixel_value = 0.0\n",
    "max_pixel_value = 1.0\n",
    "\n",
    "\n",
    "t_consumed=0\n",
    "classifier, t_consumed = CNN.train(train_images, train_labels, epochs, batch_size,\n",
    "                                   min_pixel_value, max_pixel_value, test_images, test_labels)\n",
    "\n",
    "'''# Save the model\n",
    "classifier.save(\"/home/app/Desktop/paper 6/code_CIFAR10/classifier.h5\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............EPS..........:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n",
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaad8538e694416993f381dd583f9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b386b70e25354478ba730536a4899948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 32.53 37.48 32.53 32.41\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 58.92 61.9 58.92 59.38\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.6252 - accuracy: 0.6884\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.5557 - accuracy: 0.7344\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.5317 - accuracy: 0.7532\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.5168 - accuracy: 0.7591\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.5089 - accuracy: 0.7642\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4978 - accuracy: 0.7701\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4932 - accuracy: 0.7711\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4841 - accuracy: 0.7768\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4794 - accuracy: 0.7792\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4757 - accuracy: 0.7788\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4715 - accuracy: 0.7797\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4692 - accuracy: 0.7776\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4625 - accuracy: 0.7837\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4589 - accuracy: 0.7853\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4541 - accuracy: 0.7865\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4517 - accuracy: 0.7878\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4496 - accuracy: 0.7869\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4480 - accuracy: 0.7893\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4440 - accuracy: 0.7921\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4409 - accuracy: 0.7898\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4401 - accuracy: 0.7926\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4369 - accuracy: 0.7963\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4326 - accuracy: 0.7959\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4291 - accuracy: 0.7979\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4271 - accuracy: 0.7984\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4257 - accuracy: 0.7999\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4217 - accuracy: 0.8024\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4226 - accuracy: 0.7987\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4188 - accuracy: 0.8023\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4181 - accuracy: 0.8008\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4149 - accuracy: 0.8018\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4149 - accuracy: 0.8027\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4119 - accuracy: 0.8037\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4106 - accuracy: 0.8086\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4090 - accuracy: 0.8089\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4070 - accuracy: 0.8075\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4032 - accuracy: 0.8090\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4041 - accuracy: 0.8086\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.4032 - accuracy: 0.8081\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.4026 - accuracy: 0.8069\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3963 - accuracy: 0.8129\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.3972 - accuracy: 0.8098\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3969 - accuracy: 0.8109\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3950 - accuracy: 0.8127\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3934 - accuracy: 0.8134\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3903 - accuracy: 0.8148\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3910 - accuracy: 0.8128\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3869 - accuracy: 0.8149\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3890 - accuracy: 0.8152\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3856 - accuracy: 0.8168\n",
      "NN detection: acc, prc, rec, f1: 76.9 77.0 76.9 76.87\n",
      "The number of attacked immages 1 is: 9078\n",
      "The number of clean images 0 is: 10922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 86.37 86.43 86.37 86.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 71.75 72.08 71.75 71.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9916\n",
      "The number of clean images 0 is: 10084\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 86.25 86.29 86.25 86.23\n",
      "DT detection: acc, prc, rec, f1: 64.95 64.96 64.95 64.95\n",
      "The number of attacked immages 1 is: 9110\n",
      "The number of clean images 0 is: 10890\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 85.34 85.4 85.34 85.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 72.32 72.44 72.32 72.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 10270\n",
      "The number of clean images 0 is: 9730\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.62 84.8 84.62 84.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 76.42 76.43 76.42 76.43\n",
      "The number of attacked immages 1 is: 9763\n",
      "The number of clean images 0 is: 10237\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 88.76 88.71 88.76 88.71\n",
      "XGB detection: acc, prc, rec, f1: 72.0 72.18 72.0 71.96\n",
      "The number of attacked immages 1 is: 10569\n",
      "The number of clean images 0 is: 9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 86.02 85.96 86.02 85.94\n",
      "..............EPS..........:  0.1\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d9b435961f4f728ce18ad82b6d11f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23346863b094898984156b767480a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 9.61 11.86 9.61 8.43\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 47.46 55.9 47.46 49.37\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.4441 - accuracy: 0.8209\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.3305 - accuracy: 0.8556\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3171 - accuracy: 0.8627\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3070 - accuracy: 0.8674\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.3008 - accuracy: 0.8714\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.2940 - accuracy: 0.8738\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.2888 - accuracy: 0.8771\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.2848 - accuracy: 0.8776\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.2810 - accuracy: 0.8774\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.2785 - accuracy: 0.8796\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.2755 - accuracy: 0.8816\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2722 - accuracy: 0.8844\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2696 - accuracy: 0.8834\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2667 - accuracy: 0.8834\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2640 - accuracy: 0.8841\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2615 - accuracy: 0.8870\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2595 - accuracy: 0.8879\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2552 - accuracy: 0.8886\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2549 - accuracy: 0.8909\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2533 - accuracy: 0.8901\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2490 - accuracy: 0.8916\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2485 - accuracy: 0.8938\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2469 - accuracy: 0.8928\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2451 - accuracy: 0.8941\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2448 - accuracy: 0.8929\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2434 - accuracy: 0.8941\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2393 - accuracy: 0.8954\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2376 - accuracy: 0.8967\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2370 - accuracy: 0.8990\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2352 - accuracy: 0.8989\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2332 - accuracy: 0.8976\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2303 - accuracy: 0.9010\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2288 - accuracy: 0.9004\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2279 - accuracy: 0.9023\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2246 - accuracy: 0.9012\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2243 - accuracy: 0.9032\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2228 - accuracy: 0.9044\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2241 - accuracy: 0.9035\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2202 - accuracy: 0.9042\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2204 - accuracy: 0.9035\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2190 - accuracy: 0.9043\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2166 - accuracy: 0.9073\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2151 - accuracy: 0.9071\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2156 - accuracy: 0.9066\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2117 - accuracy: 0.9086\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2129 - accuracy: 0.9071\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2109 - accuracy: 0.9098\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2102 - accuracy: 0.9101\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2087 - accuracy: 0.9084\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2061 - accuracy: 0.9104\n",
      "NN detection: acc, prc, rec, f1: 86.82 86.87 86.82 86.82\n",
      "The number of attacked immages 1 is: 9491\n",
      "The number of clean images 0 is: 10509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 81.08 81.08 81.08 80.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 85.22 85.28 85.22 85.22\n",
      "The number of attacked immages 1 is: 9949\n",
      "The number of clean images 0 is: 10051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.71 84.74 84.71 84.68\n",
      "DT detection: acc, prc, rec, f1: 79.9 79.91 79.9 79.9\n",
      "The number of attacked immages 1 is: 9820\n",
      "The number of clean images 0 is: 10180\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.93 84.01 83.93 83.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 83.75 83.75 83.75 83.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9822\n",
      "The number of clean images 0 is: 10178\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 81.67 81.75 81.67 81.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 85.48 85.48 85.48 85.48\n",
      "The number of attacked immages 1 is: 9959\n",
      "The number of clean images 0 is: 10041\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 81.81 81.75 81.81 81.73\n",
      "XGB detection: acc, prc, rec, f1: 78.77 79.7 78.77 78.63\n",
      "The number of attacked immages 1 is: 11505\n",
      "The number of clean images 0 is: 8495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 73.13 74.55 73.13 73.61\n",
      "..............EPS..........:  0.15\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ca8b781bdd4f48a074704ce2c68d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6753a59cbac34e1c9730279046223096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 5.79 8.18 5.79 4.82\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 45.55 58.7 45.55 48.87\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.2696 - accuracy: 0.8867\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.2250 - accuracy: 0.9029\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.2125 - accuracy: 0.9099\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.2051 - accuracy: 0.9133\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.1986 - accuracy: 0.9139\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1958 - accuracy: 0.9168\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1891 - accuracy: 0.9209\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1864 - accuracy: 0.9224\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1843 - accuracy: 0.9219\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1791 - accuracy: 0.9241\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1777 - accuracy: 0.9251\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1757 - accuracy: 0.9255\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1722 - accuracy: 0.9279\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1713 - accuracy: 0.9312\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1681 - accuracy: 0.9311\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1647 - accuracy: 0.9322\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1618 - accuracy: 0.9334\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1593 - accuracy: 0.9334\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1560 - accuracy: 0.9361\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1568 - accuracy: 0.9339\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1556 - accuracy: 0.9358\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 16us/sample - loss: 0.1521 - accuracy: 0.9374\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1493 - accuracy: 0.9386\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1465 - accuracy: 0.9400\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1462 - accuracy: 0.9388\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1438 - accuracy: 0.9417\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1405 - accuracy: 0.9426\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1395 - accuracy: 0.9419\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1386 - accuracy: 0.9425\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1369 - accuracy: 0.9421\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.1347 - accuracy: 0.9445\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1344 - accuracy: 0.9443\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1321 - accuracy: 0.9459\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.1304 - accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1279 - accuracy: 0.9479\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.1286 - accuracy: 0.9490\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.1249 - accuracy: 0.9511\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1250 - accuracy: 0.9499\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1250 - accuracy: 0.9485\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1220 - accuracy: 0.9492\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1206 - accuracy: 0.9504\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1176 - accuracy: 0.9541\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.1179 - accuracy: 0.9521\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1183 - accuracy: 0.9533\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.1154 - accuracy: 0.9538\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1157 - accuracy: 0.9528\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1115 - accuracy: 0.9565\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1129 - accuracy: 0.9534\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.1108 - accuracy: 0.9548\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1093 - accuracy: 0.9561\n",
      "NN detection: acc, prc, rec, f1: 90.98 90.98 90.98 90.98\n",
      "The number of attacked immages 1 is: 9935\n",
      "The number of clean images 0 is: 10065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.47 83.45 83.47 83.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 90.48 90.54 90.48 90.47\n",
      "The number of attacked immages 1 is: 9871\n",
      "The number of clean images 0 is: 10129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.09 84.09 84.09 84.05\n",
      "DT detection: acc, prc, rec, f1: 85.35 85.36 85.35 85.35\n",
      "The number of attacked immages 1 is: 9882\n",
      "The number of clean images 0 is: 10118\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.76 83.77 83.76 83.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 88.88 89.03 88.88 88.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9487\n",
      "The number of clean images 0 is: 10513\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 80.13 80.16 80.13 80.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 89.8 89.88 89.8 89.79\n",
      "The number of attacked immages 1 is: 9586\n",
      "The number of clean images 0 is: 10414\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 80.46 80.38 80.46 80.31\n",
      "XGB detection: acc, prc, rec, f1: 85.4 85.42 85.4 85.4\n",
      "The number of attacked immages 1 is: 10090\n",
      "The number of clean images 0 is: 9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 77.75 77.6 77.75 77.59\n",
      "..............EPS..........:  0.2\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab3acaaf7748748dfb708ddd1bb666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263c3a4772d0401ab4e07e60dccf6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 4.07 6.48 4.07 3.13\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.69 61.3 44.69 49.08\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.2103 - accuracy: 0.9112\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1515 - accuracy: 0.9362\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.1425 - accuracy: 0.9419\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.1370 - accuracy: 0.9423\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1332 - accuracy: 0.9451\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1302 - accuracy: 0.9474\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1248 - accuracy: 0.9488\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.1224 - accuracy: 0.9501\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.1207 - accuracy: 0.9516\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1194 - accuracy: 0.9503\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1147 - accuracy: 0.9540\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1138 - accuracy: 0.9538\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1106 - accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1107 - accuracy: 0.9546\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1081 - accuracy: 0.9566\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1049 - accuracy: 0.9582\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1041 - accuracy: 0.9582\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1020 - accuracy: 0.9597\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.1010 - accuracy: 0.9603\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0988 - accuracy: 0.9598\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0986 - accuracy: 0.9609\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0965 - accuracy: 0.9618\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0959 - accuracy: 0.9619\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0930 - accuracy: 0.9628\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0922 - accuracy: 0.9626\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0900 - accuracy: 0.9646\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0874 - accuracy: 0.9657\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0885 - accuracy: 0.9643\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0857 - accuracy: 0.9656\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0858 - accuracy: 0.9654\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0856 - accuracy: 0.9656\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0837 - accuracy: 0.9673\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0814 - accuracy: 0.9688\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0801 - accuracy: 0.9686\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0777 - accuracy: 0.9691\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0784 - accuracy: 0.9687\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0769 - accuracy: 0.9710\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0757 - accuracy: 0.9703\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0738 - accuracy: 0.9722\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0749 - accuracy: 0.9703\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0716 - accuracy: 0.9718\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0706 - accuracy: 0.9711\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0725 - accuracy: 0.9714\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0681 - accuracy: 0.9731\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0671 - accuracy: 0.9729\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0680 - accuracy: 0.9722\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0668 - accuracy: 0.9744\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0640 - accuracy: 0.9755\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0664 - accuracy: 0.9748\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0649 - accuracy: 0.9755\n",
      "NN detection: acc, prc, rec, f1: 93.58 93.58 93.58 93.57\n",
      "The number of attacked immages 1 is: 9893\n",
      "The number of clean images 0 is: 10107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.61 83.55 83.61 83.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 93.8 93.85 93.8 93.8\n",
      "The number of attacked immages 1 is: 9917\n",
      "The number of clean images 0 is: 10083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.34 84.32 84.34 84.3\n",
      "DT detection: acc, prc, rec, f1: 90.4 90.4 90.4 90.4\n",
      "The number of attacked immages 1 is: 9987\n",
      "The number of clean images 0 is: 10013\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.3 84.3 84.3 84.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 93.12 93.2 93.12 93.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9670\n",
      "The number of clean images 0 is: 10330\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 81.48 81.38 81.48 81.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 93.18 93.2 93.18 93.17\n",
      "The number of attacked immages 1 is: 9698\n",
      "The number of clean images 0 is: 10302\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 81.4 81.25 81.4 81.26\n",
      "XGB detection: acc, prc, rec, f1: 89.38 89.87 89.38 89.34\n",
      "The number of attacked immages 1 is: 8788\n",
      "The number of clean images 0 is: 11212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 73.86 73.64 73.86 73.64\n",
      "..............EPS..........:  0.25\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ed8e4a422d49afb7f2a06b90fcbbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6d3d79dc2449f59681c0feac485ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 4.41 10.22 4.41 3.43\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.86 64.22 44.86 50.05\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.1738 - accuracy: 0.9287\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1220 - accuracy: 0.9492\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1161 - accuracy: 0.9524\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1096 - accuracy: 0.9538\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.1065 - accuracy: 0.9556\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.1033 - accuracy: 0.9564\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.1012 - accuracy: 0.9576\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0992 - accuracy: 0.9576\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0968 - accuracy: 0.9586\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 1s 35us/sample - loss: 0.0937 - accuracy: 0.9598\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0930 - accuracy: 0.9616\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0899 - accuracy: 0.9618\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9614\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0860 - accuracy: 0.9649\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0849 - accuracy: 0.9631\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0814 - accuracy: 0.9666\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0800 - accuracy: 0.9653\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0798 - accuracy: 0.9673\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0767 - accuracy: 0.9677\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0753 - accuracy: 0.9688\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0737 - accuracy: 0.9705\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0729 - accuracy: 0.9704\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0707 - accuracy: 0.9701\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0697 - accuracy: 0.9714\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0680 - accuracy: 0.9719\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0658 - accuracy: 0.9736\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0645 - accuracy: 0.9741\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0641 - accuracy: 0.9739\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0622 - accuracy: 0.9743\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0618 - accuracy: 0.9749\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0606 - accuracy: 0.9758\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0598 - accuracy: 0.9764\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0583 - accuracy: 0.9772\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0567 - accuracy: 0.9781\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0539 - accuracy: 0.9791\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0552 - accuracy: 0.9775\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0528 - accuracy: 0.9791\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0516 - accuracy: 0.9794\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0507 - accuracy: 0.9810\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0509 - accuracy: 0.9799\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0484 - accuracy: 0.9821\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0470 - accuracy: 0.9822\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0484 - accuracy: 0.9806\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0468 - accuracy: 0.9817\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0463 - accuracy: 0.9827\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0466 - accuracy: 0.9828\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0442 - accuracy: 0.9833\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0426 - accuracy: 0.9850\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0413 - accuracy: 0.9846\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0414 - accuracy: 0.9851\n",
      "NN detection: acc, prc, rec, f1: 95.08 95.09 95.08 95.07\n",
      "The number of attacked immages 1 is: 9856\n",
      "The number of clean images 0 is: 10144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.77 83.71 83.77 83.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 95.85 95.9 95.85 95.85\n",
      "The number of attacked immages 1 is: 9924\n",
      "The number of clean images 0 is: 10076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.7 84.67 84.7 84.65\n",
      "DT detection: acc, prc, rec, f1: 92.68 92.68 92.68 92.68\n",
      "The number of attacked immages 1 is: 10008\n",
      "The number of clean images 0 is: 9992\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.69 84.7 84.69 84.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 95.2 95.23 95.2 95.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9710\n",
      "The number of clean images 0 is: 10290\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 82.62 82.56 82.62 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 95.55 95.58 95.55 95.55\n",
      "The number of attacked immages 1 is: 9655\n",
      "The number of clean images 0 is: 10345\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.11 81.95 82.11 81.93\n",
      "XGB detection: acc, prc, rec, f1: 92.07 92.59 92.07 92.05\n",
      "The number of attacked immages 1 is: 8738\n",
      "The number of clean images 0 is: 11262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 75.33 75.28 75.33 75.26\n",
      "..............EPS..........:  0.3\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c63fa634d844aac98105b491fb65725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893a1c1528b049dc9f618b0952fb66a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 3.41 7.53 3.41 2.17\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.36 64.37 44.36 49.83\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.1379 - accuracy: 0.9409\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.1056 - accuracy: 0.9536\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0977 - accuracy: 0.9585\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0941 - accuracy: 0.9606\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0899 - accuracy: 0.9612\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0876 - accuracy: 0.9619\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0851 - accuracy: 0.9624\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0836 - accuracy: 0.9638\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0793 - accuracy: 0.9663\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0794 - accuracy: 0.9666\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0768 - accuracy: 0.9672\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0751 - accuracy: 0.9681\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0729 - accuracy: 0.9697\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0714 - accuracy: 0.9708\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0698 - accuracy: 0.9717\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0695 - accuracy: 0.9716\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0675 - accuracy: 0.9731\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0658 - accuracy: 0.9730\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0644 - accuracy: 0.9735\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0622 - accuracy: 0.9742\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0619 - accuracy: 0.9751\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0604 - accuracy: 0.9753\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0596 - accuracy: 0.9766\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0586 - accuracy: 0.9762\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0581 - accuracy: 0.9779\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0565 - accuracy: 0.9776\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0551 - accuracy: 0.9779\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0547 - accuracy: 0.9782\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0537 - accuracy: 0.9785\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0522 - accuracy: 0.9794\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0506 - accuracy: 0.9794\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0499 - accuracy: 0.9804\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0486 - accuracy: 0.9806\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0481 - accuracy: 0.9801\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0457 - accuracy: 0.9811\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0468 - accuracy: 0.9817\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0454 - accuracy: 0.9824\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0445 - accuracy: 0.9824\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0435 - accuracy: 0.9831\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0437 - accuracy: 0.9832\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0428 - accuracy: 0.9827\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0437 - accuracy: 0.9827\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0408 - accuracy: 0.9841\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0417 - accuracy: 0.9838\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0379 - accuracy: 0.9853\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0367 - accuracy: 0.9860\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0371 - accuracy: 0.9852\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0382 - accuracy: 0.9855\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0338 - accuracy: 0.9872\n",
      "NN detection: acc, prc, rec, f1: 96.28 96.29 96.28 96.27\n",
      "The number of attacked immages 1 is: 10097\n",
      "The number of clean images 0 is: 9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.9 83.95 83.9 83.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 96.48 96.48 96.48 96.47\n",
      "The number of attacked immages 1 is: 9978\n",
      "The number of clean images 0 is: 10022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.81 84.8 84.81 84.77\n",
      "DT detection: acc, prc, rec, f1: 94.2 94.22 94.2 94.2\n",
      "The number of attacked immages 1 is: 10037\n",
      "The number of clean images 0 is: 9963\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.45 84.48 84.45 84.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 96.1 96.1 96.1 96.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9925\n",
      "The number of clean images 0 is: 10075\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.35 83.24 83.35 83.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 96.28 96.28 96.28 96.27\n",
      "The number of attacked immages 1 is: 9840\n",
      "The number of clean images 0 is: 10160\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.74 82.57 82.74 82.6\n",
      "XGB detection: acc, prc, rec, f1: 92.85 93.44 92.85 92.82\n",
      "The number of attacked immages 1 is: 8574\n",
      "The number of clean images 0 is: 11426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 74.48 74.89 74.48 74.35\n",
      "..............EPS..........:  0.35\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c57b133c5da430d9384dbb2920051c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd0c7e8e1bf480eab2cfb95b2c084e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 3.27 7.42 3.27 2.11\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.29 65.84 44.29 50.35\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.1313 - accuracy: 0.9450\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0984 - accuracy: 0.9586\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0897 - accuracy: 0.9636\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0855 - accuracy: 0.9668\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0823 - accuracy: 0.9660\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0798 - accuracy: 0.9683\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0766 - accuracy: 0.9697\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0741 - accuracy: 0.9702\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0726 - accuracy: 0.9715\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0699 - accuracy: 0.9732\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0670 - accuracy: 0.9736\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0659 - accuracy: 0.9746\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0643 - accuracy: 0.9754\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0607 - accuracy: 0.9770\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0594 - accuracy: 0.9769\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0571 - accuracy: 0.9783\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0566 - accuracy: 0.9789\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0540 - accuracy: 0.9795\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0540 - accuracy: 0.9797\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0530 - accuracy: 0.9781\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0504 - accuracy: 0.9812\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0494 - accuracy: 0.9807\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0482 - accuracy: 0.9826\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0466 - accuracy: 0.9822\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0452 - accuracy: 0.9830\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0441 - accuracy: 0.9833\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0434 - accuracy: 0.9830\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0426 - accuracy: 0.9836\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0428 - accuracy: 0.9837\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 30us/sample - loss: 0.0391 - accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0390 - accuracy: 0.9858\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0381 - accuracy: 0.9859\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 31us/sample - loss: 0.0371 - accuracy: 0.9856\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0352 - accuracy: 0.9871\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0356 - accuracy: 0.9870\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0344 - accuracy: 0.9874\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0327 - accuracy: 0.9886\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0374 - accuracy: 0.9864\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0327 - accuracy: 0.9876\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0317 - accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0307 - accuracy: 0.9896\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0305 - accuracy: 0.9899\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0318 - accuracy: 0.9882\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0293 - accuracy: 0.9898\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0279 - accuracy: 0.9901\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0281 - accuracy: 0.9897\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0299 - accuracy: 0.9894\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0267 - accuracy: 0.9906\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0258 - accuracy: 0.9914\n",
      "NN detection: acc, prc, rec, f1: 96.95 96.95 96.95 96.95\n",
      "The number of attacked immages 1 is: 10006\n",
      "The number of clean images 0 is: 9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.79 84.75 84.79 84.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 96.98 97.0 96.98 96.97\n",
      "The number of attacked immages 1 is: 9955\n",
      "The number of clean images 0 is: 10045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.85 84.82 84.85 84.8\n",
      "DT detection: acc, prc, rec, f1: 93.85 93.86 93.85 93.85\n",
      "The number of attacked immages 1 is: 10022\n",
      "The number of clean images 0 is: 9978\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.64 84.67 84.64 84.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 96.58 96.58 96.58 96.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9767\n",
      "The number of clean images 0 is: 10233\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.08 82.88 83.08 82.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 96.68 96.7 96.68 96.67\n",
      "The number of attacked immages 1 is: 9683\n",
      "The number of clean images 0 is: 10317\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.43 82.18 82.43 82.21\n",
      "XGB detection: acc, prc, rec, f1: 93.5 94.08 93.5 93.47\n",
      "The number of attacked immages 1 is: 8723\n",
      "The number of clean images 0 is: 11277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 75.9 75.59 75.9 75.6\n",
      "..............EPS..........:  0.4\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f43a899ccb54a81a5265b6917269d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ede94ff29e4066a9459c4ef0bdaa83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 3.24 6.41 3.24 1.91\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.28 67.15 44.28 50.71\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.1252 - accuracy: 0.9484\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0724 - accuracy: 0.9727\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0658 - accuracy: 0.9752\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0572 - accuracy: 0.9792\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0542 - accuracy: 0.9797\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0540 - accuracy: 0.9796\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0514 - accuracy: 0.9810\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0495 - accuracy: 0.9814\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0484 - accuracy: 0.9818\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0470 - accuracy: 0.9827\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0442 - accuracy: 0.9837\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0438 - accuracy: 0.9830\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0411 - accuracy: 0.9844\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0409 - accuracy: 0.9850\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0409 - accuracy: 0.9842\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0382 - accuracy: 0.9863\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0377 - accuracy: 0.9858\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0356 - accuracy: 0.9862\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0365 - accuracy: 0.9866\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0342 - accuracy: 0.9862\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0318 - accuracy: 0.9872\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0313 - accuracy: 0.9883\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0304 - accuracy: 0.9887\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0298 - accuracy: 0.9886\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0291 - accuracy: 0.9892\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0282 - accuracy: 0.9893\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0272 - accuracy: 0.9896\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0266 - accuracy: 0.9898\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0243 - accuracy: 0.9903\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0260 - accuracy: 0.9904\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0229 - accuracy: 0.9915\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0241 - accuracy: 0.9910\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0225 - accuracy: 0.9919\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0234 - accuracy: 0.9908\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0228 - accuracy: 0.9914\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0212 - accuracy: 0.9919\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0203 - accuracy: 0.9920\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0199 - accuracy: 0.9924\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0198 - accuracy: 0.9919\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0174 - accuracy: 0.9938\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0173 - accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0157 - accuracy: 0.9946\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0148 - accuracy: 0.9943\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0149 - accuracy: 0.9944\n",
      "NN detection: acc, prc, rec, f1: 97.98 97.98 97.98 97.97\n",
      "The number of attacked immages 1 is: 9962\n",
      "The number of clean images 0 is: 10038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.78 84.75 84.78 84.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 97.48 97.49 97.48 97.47\n",
      "The number of attacked immages 1 is: 9969\n",
      "The number of clean images 0 is: 10031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.91 84.89 84.91 84.87\n",
      "DT detection: acc, prc, rec, f1: 95.5 95.5 95.5 95.5\n",
      "The number of attacked immages 1 is: 10012\n",
      "The number of clean images 0 is: 9988\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.81 84.81 84.81 84.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 97.45 97.45 97.45 97.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9929\n",
      "The number of clean images 0 is: 10071\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.94 83.83 83.94 83.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 97.2 97.2 97.2 97.2\n",
      "The number of attacked immages 1 is: 9839\n",
      "The number of clean images 0 is: 10161\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.45 83.27 83.45 83.32\n",
      "XGB detection: acc, prc, rec, f1: 94.25 94.7 94.25 94.23\n",
      "The number of attacked immages 1 is: 8830\n",
      "The number of clean images 0 is: 11170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 76.64 76.45 76.64 76.31\n",
      "..............EPS..........:  0.45\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81baf2c316ca4be49fde5a753232de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a3d06d4b3847bb84e2658a3483e79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 3.46 8.21 3.46 2.18\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.39 67.21 44.39 50.95\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.1253 - accuracy: 0.9431\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0950 - accuracy: 0.9579\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0849 - accuracy: 0.9637\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0801 - accuracy: 0.9676\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0766 - accuracy: 0.9692\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0746 - accuracy: 0.9691\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0715 - accuracy: 0.9704\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0693 - accuracy: 0.9712\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0655 - accuracy: 0.9734\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0634 - accuracy: 0.9729\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0629 - accuracy: 0.9750\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0597 - accuracy: 0.9750\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0581 - accuracy: 0.9758\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0560 - accuracy: 0.9781\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0538 - accuracy: 0.9780\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0541 - accuracy: 0.9784\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0525 - accuracy: 0.9791\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0496 - accuracy: 0.9787\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0481 - accuracy: 0.9797\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0473 - accuracy: 0.9801\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0452 - accuracy: 0.9808\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0443 - accuracy: 0.9822\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0433 - accuracy: 0.9822\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.0424 - accuracy: 0.9823\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0429 - accuracy: 0.9826\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0416 - accuracy: 0.9826\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0393 - accuracy: 0.9848\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0382 - accuracy: 0.9850\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0369 - accuracy: 0.9858\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0370 - accuracy: 0.9847\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0358 - accuracy: 0.9852\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0336 - accuracy: 0.9862\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0327 - accuracy: 0.9879\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0318 - accuracy: 0.9884\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0310 - accuracy: 0.9883\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0333 - accuracy: 0.9869\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.0300 - accuracy: 0.9882\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0306 - accuracy: 0.9885\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0292 - accuracy: 0.9887\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0268 - accuracy: 0.9891\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0271 - accuracy: 0.9899\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0263 - accuracy: 0.9892\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0271 - accuracy: 0.9900\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0231 - accuracy: 0.9912\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0229 - accuracy: 0.9913\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0250 - accuracy: 0.9909\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0240 - accuracy: 0.9912\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0206 - accuracy: 0.9920\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0244 - accuracy: 0.9908\n",
      "NN detection: acc, prc, rec, f1: 97.18 97.19 97.18 97.17\n",
      "The number of attacked immages 1 is: 9865\n",
      "The number of clean images 0 is: 10135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.23 84.17 84.23 84.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 97.18 97.18 97.18 97.17\n",
      "The number of attacked immages 1 is: 9972\n",
      "The number of clean images 0 is: 10028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.89 84.88 84.89 84.85\n",
      "DT detection: acc, prc, rec, f1: 94.15 94.16 94.15 94.15\n",
      "The number of attacked immages 1 is: 10030\n",
      "The number of clean images 0 is: 9970\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 84.69 84.7 84.69 84.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 96.45 96.45 96.45 96.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9938\n",
      "The number of clean images 0 is: 10062\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.74 83.61 83.74 83.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 96.52 96.54 96.52 96.52\n",
      "The number of attacked immages 1 is: 9790\n",
      "The number of clean images 0 is: 10210\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.96 82.77 82.96 82.78\n",
      "XGB detection: acc, prc, rec, f1: 93.12 93.72 93.12 93.1\n",
      "The number of attacked immages 1 is: 8664\n",
      "The number of clean images 0 is: 11336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 75.39 75.19 75.39 74.93\n",
      "..............EPS..........:  0.5\n",
      "acc, prc, rec, f1: 85.31 85.33 85.31 85.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c5346b58e0486c88ad8c35467d4da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - restarts', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bda214b7ec4d4cb7fdeb55c66a325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SquareAttack - iterations', style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc, prc, rec, f1: 2.9 3.87 2.9 1.39\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 44.1 67.75 44.1 50.83\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.0910 - accuracy: 0.9621\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0566 - accuracy: 0.9787\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0511 - accuracy: 0.9816\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.0476 - accuracy: 0.9823\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0465 - accuracy: 0.9828\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0431 - accuracy: 0.9850\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0407 - accuracy: 0.9850\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0368 - accuracy: 0.9857\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0355 - accuracy: 0.9879\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0337 - accuracy: 0.9880\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0320 - accuracy: 0.9884\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0309 - accuracy: 0.9899\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0308 - accuracy: 0.9887\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0275 - accuracy: 0.9900\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0275 - accuracy: 0.9899\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0276 - accuracy: 0.9901\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0249 - accuracy: 0.9904\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0238 - accuracy: 0.9916\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.0231 - accuracy: 0.9919\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0206 - accuracy: 0.9921\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0201 - accuracy: 0.9926\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0207 - accuracy: 0.9929\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0192 - accuracy: 0.9929\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.0193 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.9939\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0142 - accuracy: 0.9948\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9935\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.9940\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.0142 - accuracy: 0.9949\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0125 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0109 - accuracy: 0.9959\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0094 - accuracy: 0.9965\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0094 - accuracy: 0.9961\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0116 - accuracy: 0.9956\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0101 - accuracy: 0.9963\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9965\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9979\n",
      "NN detection: acc, prc, rec, f1: 98.22 98.23 98.22 98.23\n",
      "The number of attacked immages 1 is: 10012\n",
      "The number of clean images 0 is: 9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 85.04 85.05 85.04 85.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 98.28 98.29 98.28 98.27\n",
      "The number of attacked immages 1 is: 9960\n",
      "The number of clean images 0 is: 10040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.92 84.9 84.92 84.88\n",
      "DT detection: acc, prc, rec, f1: 96.25 96.25 96.25 96.25\n",
      "The number of attacked immages 1 is: 10006\n",
      "The number of clean images 0 is: 9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 84.77 84.76 84.77 84.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 97.75 97.76 97.75 97.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9872\n",
      "The number of clean images 0 is: 10128\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.75 83.6 83.75 83.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 98.22 98.24 98.22 98.22\n",
      "The number of attacked immages 1 is: 9828\n",
      "The number of clean images 0 is: 10172\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.58 83.41 83.58 83.44\n",
      "XGB detection: acc, prc, rec, f1: 93.82 94.41 93.82 93.8\n",
      "The number of attacked immages 1 is: 8689\n",
      "The number of clean images 0 is: 11311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 75.54 75.48 75.54 75.14\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 55, 5):\n",
    "    eps_FSGM= (i/100)\n",
    "    print(\"..............EPS..........: \", eps_FSGM)\n",
    "    #Evaluate the model\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, test_images, test_labels)\n",
    "\n",
    "    #write the results\n",
    "    import Writer\n",
    "    results =\"===========\\n\" +  dataset + \"-Regular:\\n acc, prc, rec, f1, epochs, batch size, time: acc, prc, rec, f1\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(epochs)+ \",\" + str(batch_size) + \",\" + str(int(t_consumed)) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "    #==================================\n",
    "    \n",
    "    # Extract the features for the regular images\n",
    "    from tensorflow.keras import models\n",
    "\n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_regular = model_output.predict(test_images)\n",
    "    print(Features_regular.shape)   \n",
    "    #==================================\n",
    "\n",
    "    # Generate adversarial examples using the FastGradientMethod attack\n",
    "    from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent #white-box\n",
    "    from art.attacks.evasion import ZooAttack, SquareAttack, BoundaryAttack #black-box\n",
    "\n",
    "\n",
    "    # Initialize the attack\n",
    "    attack = None\n",
    "\n",
    "    # Select the attack\n",
    "    if attack_type == \"FGSM\":\n",
    "        attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "    if attack_type == \"BIM\":\n",
    "        attack = BasicIterativeMethod(estimator=classifier, eps=eps_FSGM)\n",
    "    elif attack_type == \"PGD\":\n",
    "        attack = ProjectedGradientDescent(estimator=classifier, eps=eps_FSGM)\n",
    "    elif attack_type == \"SA\":\n",
    "        attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "    elif attack_type == \"ZA\":\n",
    "        attack = ZooAttack(classifier=classifier, max_iter=2, learning_rate=eps_FSGM)\n",
    "\n",
    "    adv_images = attack.generate(test_images)\n",
    "    #=============================================\n",
    "    \n",
    "    # Evaluate the model on the adversarial test set images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, adv_images, test_labels)\n",
    "\n",
    "    #write the results\n",
    "    results =dataset + \"-Adversarial:\\n acc, prc, rec, f1, epochs, attack_type, eps_FSGM\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + attack_type + \",\" + str(eps_FSGM) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "    #=============================================\n",
    "\n",
    "    # Extract the features for the adversarial images\n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_adversarial = model_output.predict(adv_images)\n",
    "    print(Features_adversarial.shape)\n",
    "    #=============================================\n",
    "\n",
    "    # merge regular and feature test images\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    #merge data features of regular and adversarial images\n",
    "    reg_adv_images = np.concatenate((Features_regular, Features_adversarial), axis=0)\n",
    "\n",
    "    # generate labels for regular and adversarial, and merge them\n",
    "\n",
    "    label_reg = np.zeros((10000, 1))\n",
    "    label_adv = np.ones((10000, 1))\n",
    "    reg_adv_labels=np.concatenate((label_reg, label_adv), axis=0)\n",
    "\n",
    "    print(\"data details: \", reg_adv_images.shape, \" , labels: \", reg_adv_labels.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reg_adv_images, reg_adv_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "    #fractin to use a part of the merged regular and adversarial images\n",
    "    fraction=1\n",
    "    #reduce the length because the memory is out\n",
    "    X_train=X_train[:int(X_train.shape[0]/fraction)]\n",
    "    X_test=X_test[:(int(X_test.shape[0]/fraction))]\n",
    "    y_train=y_train[:(int(y_train.shape[0]/fraction))]\n",
    "    y_test=y_test[:(int(y_test.shape[0]/fraction))]\n",
    "    X_train, X_test, y_train, y_test\n",
    "    print(\"data after split : X_train, X_test, y_train, y_test\\n\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    # integrate the adversarial detector model to CNN to exclude adversarial images or outlier images.\n",
    "\n",
    "    size_advs=10000\n",
    "    test_reg_adv_images=np.concatenate((test_images,adv_images[:size_advs]), axis=0)\n",
    "    test_reg_adv_labels=np.concatenate((test_labels,test_labels[:size_advs]), axis=0)\n",
    "    print(test_reg_adv_images.shape, test_reg_adv_labels.shape)\n",
    "\n",
    "    # Shuffle the data\n",
    "    indices = np.arange(len(test_reg_adv_images))\n",
    "    np.random.shuffle(indices)\n",
    "    test_reg_adv_images= test_reg_adv_images[indices]\n",
    "    test_reg_adv_labels = test_reg_adv_labels[indices]\n",
    "\n",
    "    # Evaluate the model after integrate regular and adversarial images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, test_reg_adv_images, test_reg_adv_labels)\n",
    "    results =dataset + \"-Regular+Adversarial:\\n acc, prc, rec, f1\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    # Extract features \n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_adv_reg = model_output.predict(test_reg_adv_images)\n",
    "    print(Features_adversarial.shape)\n",
    "    #=============================================\n",
    "\n",
    "    #to ensure that the size of regular and adversarial image size are the same to do fair evaluation\n",
    "    def make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels):\n",
    "        diff=int(np.absolute(clean_images.shape[0] - attacked_images.shape[0])/2)\n",
    "        size=int((clean_images.shape[0]+attacked_images.shape[0])/2)\n",
    "        temp_clean_images=np.ones((size,32,32,3))\n",
    "        temp_attacked_images=np.ones((size,32,32,3))\n",
    "\n",
    "        temp_clean_labels=np.ones((size,1))\n",
    "        temp_attacked_labels=np.ones((size,1))\n",
    "\n",
    "        if(clean_images.shape[0]>attacked_images.shape[0]):\n",
    "            temp_clean_images=clean_images[:size]\n",
    "            temp_clean_labels=clean_labels[:size]\n",
    "\n",
    "            temp_attacked_images=np.concatenate((attacked_images,clean_images[-diff:]), axis=0)\n",
    "            temp_attacked_labels=np.concatenate((temp_attacked_labels,clean_labels[-diff:]), axis=0)\n",
    "\n",
    "        elif(clean_images.shape[0]<attacked_images.shape[0]):\n",
    "            temp_attacked_images=attacked_images[:size]\n",
    "            temp_attacked_labels=attacked_labels[:size]\n",
    "\n",
    "            temp_clean_images=np.concatenate((clean_images,attacked_images[-diff:]), axis=0)\n",
    "            temp_clean_labels=np.concatenate((clean_labels,attacked_labels[-diff:]), axis=0)\n",
    "\n",
    "        clean_images=temp_clean_images\n",
    "        clean_labels=temp_clean_labels\n",
    "\n",
    "        attacked_images=temp_attacked_images\n",
    "        attacked_labels=temp_attacked_labels\n",
    "\n",
    "        #print(\"clean_images.shape, attacked_images.shape\", clean_images.shape, attacked_images.shape)\n",
    "        #print(\"clean_labels.shape, attacked_labels.shape\", clean_labels.shape, attacked_labels.shape)\n",
    "\n",
    "        return clean_images,clean_labels, attacked_images, attacked_labels\n",
    "\n",
    "    #Exclude adversarial images from testing and use only the regular images\n",
    "\n",
    "    def retrurn_clean_images(adv_images_pred_binary):\n",
    "\n",
    "        # Count the number of times 1 appears in the array\n",
    "        number_of_1s = np.count_nonzero(adv_images_pred_binary == 1)\n",
    "        # Count the number of times 0 appears in the array\n",
    "        number_of_0s = np.count_nonzero(adv_images_pred_binary == 0)\n",
    "        print(\"The number of attacked immages 1 is:\", number_of_1s)\n",
    "        print(\"The number of clean images 0 is:\", number_of_0s)\n",
    "\n",
    "        #Exclude adversarial images from testing and use only the regular images\n",
    "        # Create a boolean mask use only the clean images\n",
    "        mask_clean = np.where(adv_images_pred_binary == 0)[0]\n",
    "        mask_adv = np.where(adv_images_pred_binary == 1)[0]\n",
    "\n",
    "        # Exclude adversarial images\n",
    "        #clean images\n",
    "        clean_images = test_reg_adv_images[mask_clean]\n",
    "        clean_labels = test_reg_adv_labels[mask_clean]\n",
    "        #Adversarial images,attacked images\n",
    "        attacked_images = test_reg_adv_images[mask_adv]\n",
    "        attacked_labels = test_reg_adv_labels[mask_adv]\n",
    "\n",
    "        clean_images,clean_labels, attacked_images, attacked_labels = make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels)\n",
    "\n",
    "        print(\"clean_images:\", clean_images.shape)\n",
    "        print(\"clean_labels:\", clean_labels.shape)\n",
    "\n",
    "        return clean_images, clean_labels\n",
    "\n",
    "\n",
    "    def eval_model_after_exclude_adv_image(model_name, new_test_clean_images, new_test_clean_labels, t_consumed):# Evaluate the model after excluding the adversarial images\n",
    "        acc, prc, rec, f1 = CNN.test(classifier, new_test_clean_images, new_test_clean_labels)\n",
    "        results =model_name + \":\\n acc, prc, rec, f1, time_detection\\n\"\n",
    "        results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(int(t_consumed)) + \"\\n\" \n",
    "        Writer.write_results(results, path)\n",
    "    #=============================================\n",
    "\n",
    "    #Evaluate the mosdel after inegrate NN as outlier detection to exclude Adversarial images\n",
    "    import ML_Classifiers as MLC\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.NN(X_train, X_test, y_train, y_test,eps_FSGM, attack_type, Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+NN_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate RF as outlier detection to exclude Adversarial images\n",
    "    import ML_Classifiers as MLC\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.Random_Forest(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+RF_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate DT as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "    adv_images_pred_binary= MLC.DT(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+DT_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate KNN as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "    adv_images_pred_binary= MLC.KNN(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+KNN_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate GBM as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.GBM(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+GBM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate XGB as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.XGB(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+XGB_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............EPS..........:  0.05\n",
      "859  values were replaced from  1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-df25dc4ad959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mArtMap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0madv_images_pred_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArtMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatures_adv_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0madv_images_pred_binary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_images_pred_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/paper 6/code_CIFAR10/FAM.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(x_test, y_test, ArtMap, adv_reg_images)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0my_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m#y_predict=[y_predict[i]['index'] for i in range(len_y)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/paper 6/code_CIFAR10/FAM.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0my_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m#y_predict=[y_predict[i]['index'] for i in range(len_y)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate FAM as outlier detection to exclude Adversarial images\n",
    "\n",
    "for i in range(5, 55, 5):\n",
    "    eps_FSGM= (i/100)\n",
    "    print(\"..............EPS..........: \", eps_FSGM)\n",
    "\n",
    "    import FAM \n",
    "\n",
    "    t_str=time.time()\n",
    "    ArtMap=FAM.train(X_train[:5000], y_train[:5000])\n",
    "\n",
    "    adv_images_pred_binary = FAM.test(X_test[:1000], y_test[:1000], ArtMap, Features_adv_reg)\n",
    "\n",
    "    adv_images_pred_binary=np.array(adv_images_pred_binary)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+FAM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
