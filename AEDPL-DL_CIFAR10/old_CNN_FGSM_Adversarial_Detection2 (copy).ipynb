{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import CNN # External class generated for CNN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "epochs=75\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "eps_FSGM=0.30\n",
    "\n",
    "# Select the attacker\n",
    "#White-box: \"FGSM\", \"BIM\", \"PGD\", \n",
    "#Black-box: \"SA\",\"ZA\"\n",
    "attack_type = \"FGSM\"\n",
    "dataset=\"CIRFAR10\"   # MNIST, CIRFAR10\n",
    "\n",
    "#path='results/MNIST_BA.txt' #this for MNIST images\n",
    "path='results/CIRFAR10/CIRFAR10_FGSM.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/app/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/75\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.6926 - accuracy: 0.3856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 1.6926 - accuracy: 0.3856 - val_loss: 1.9634 - val_accuracy: 0.2788\n",
      "Epoch 2/75\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 1.1879 - accuracy: 0.5831 - val_loss: 0.9861 - val_accuracy: 0.6521\n",
      "Epoch 3/75\n",
      "50000/50000 [==============================] - 113s 2ms/sample - loss: 0.9578 - accuracy: 0.6751 - val_loss: 0.8864 - val_accuracy: 0.6985\n",
      "Epoch 4/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.8330 - accuracy: 0.7199 - val_loss: 0.9399 - val_accuracy: 0.6875\n",
      "Epoch 5/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.7399 - accuracy: 0.7540 - val_loss: 0.6697 - val_accuracy: 0.7781\n",
      "Epoch 6/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.6713 - accuracy: 0.7763 - val_loss: 0.7061 - val_accuracy: 0.7678\n",
      "Epoch 7/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.6180 - accuracy: 0.7935 - val_loss: 0.6195 - val_accuracy: 0.7877\n",
      "Epoch 8/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.5572 - accuracy: 0.8141 - val_loss: 0.5796 - val_accuracy: 0.8054\n",
      "Epoch 9/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.5185 - accuracy: 0.8267 - val_loss: 0.6072 - val_accuracy: 0.8014\n",
      "Epoch 10/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4881 - accuracy: 0.8368 - val_loss: 0.6095 - val_accuracy: 0.8050\n",
      "Epoch 11/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4543 - accuracy: 0.8479 - val_loss: 0.5775 - val_accuracy: 0.8115\n",
      "Epoch 12/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4172 - accuracy: 0.8601 - val_loss: 0.5524 - val_accuracy: 0.8249\n",
      "Epoch 13/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3991 - accuracy: 0.8665 - val_loss: 0.6062 - val_accuracy: 0.8161\n",
      "Epoch 14/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3770 - accuracy: 0.8732 - val_loss: 0.5810 - val_accuracy: 0.8224\n",
      "Epoch 15/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3516 - accuracy: 0.8825 - val_loss: 0.5640 - val_accuracy: 0.8234\n",
      "Epoch 16/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3362 - accuracy: 0.8875 - val_loss: 0.6107 - val_accuracy: 0.8228\n",
      "Epoch 17/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3194 - accuracy: 0.8934 - val_loss: 0.7591 - val_accuracy: 0.7836\n",
      "Epoch 18/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3100 - accuracy: 0.8955 - val_loss: 0.5619 - val_accuracy: 0.8324\n",
      "Epoch 19/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2873 - accuracy: 0.9034 - val_loss: 0.6560 - val_accuracy: 0.8143\n",
      "Epoch 20/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2682 - accuracy: 0.9111 - val_loss: 0.5759 - val_accuracy: 0.8374\n",
      "Epoch 21/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2586 - accuracy: 0.9127 - val_loss: 0.6103 - val_accuracy: 0.8309\n",
      "Epoch 22/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2558 - accuracy: 0.9141 - val_loss: 0.5931 - val_accuracy: 0.8350\n",
      "Epoch 23/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2388 - accuracy: 0.9194 - val_loss: 0.6098 - val_accuracy: 0.8352\n",
      "Epoch 24/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2275 - accuracy: 0.9237 - val_loss: 0.5937 - val_accuracy: 0.8406\n",
      "Epoch 25/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2151 - accuracy: 0.9267 - val_loss: 0.5937 - val_accuracy: 0.8408\n",
      "Epoch 26/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2117 - accuracy: 0.9296 - val_loss: 0.6299 - val_accuracy: 0.8336\n",
      "Epoch 27/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2062 - accuracy: 0.9310 - val_loss: 0.5795 - val_accuracy: 0.8437\n",
      "Epoch 28/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1964 - accuracy: 0.9342 - val_loss: 0.5938 - val_accuracy: 0.8414\n",
      "Epoch 29/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1863 - accuracy: 0.9369 - val_loss: 0.6463 - val_accuracy: 0.8346\n",
      "Epoch 30/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1844 - accuracy: 0.9385 - val_loss: 0.7421 - val_accuracy: 0.8212\n",
      "Epoch 31/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1805 - accuracy: 0.9397 - val_loss: 0.6225 - val_accuracy: 0.8412\n",
      "Epoch 32/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1702 - accuracy: 0.9436 - val_loss: 0.6181 - val_accuracy: 0.8433\n",
      "Epoch 33/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1710 - accuracy: 0.9428 - val_loss: 0.5986 - val_accuracy: 0.8449\n",
      "Epoch 34/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1586 - accuracy: 0.9465 - val_loss: 0.6051 - val_accuracy: 0.8469\n",
      "Epoch 35/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1543 - accuracy: 0.9487 - val_loss: 0.7438 - val_accuracy: 0.8227\n",
      "Epoch 36/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1520 - accuracy: 0.9494 - val_loss: 0.6880 - val_accuracy: 0.8348\n",
      "Epoch 37/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1501 - accuracy: 0.9496 - val_loss: 0.6495 - val_accuracy: 0.8457\n",
      "Epoch 38/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1431 - accuracy: 0.9525 - val_loss: 0.6451 - val_accuracy: 0.8461\n",
      "Epoch 39/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1397 - accuracy: 0.9529 - val_loss: 0.6475 - val_accuracy: 0.8495\n",
      "Epoch 40/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1391 - accuracy: 0.9546 - val_loss: 0.6477 - val_accuracy: 0.8487\n",
      "Epoch 41/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1319 - accuracy: 0.9555 - val_loss: 0.7007 - val_accuracy: 0.8451\n",
      "Epoch 42/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1293 - accuracy: 0.9573 - val_loss: 0.6759 - val_accuracy: 0.8465\n",
      "Epoch 43/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1296 - accuracy: 0.9570 - val_loss: 0.7198 - val_accuracy: 0.8444\n",
      "Epoch 44/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1278 - accuracy: 0.9574 - val_loss: 0.6746 - val_accuracy: 0.8488\n",
      "Epoch 45/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1233 - accuracy: 0.9593 - val_loss: 0.7261 - val_accuracy: 0.8370\n",
      "Epoch 46/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1180 - accuracy: 0.9604 - val_loss: 0.6733 - val_accuracy: 0.8489\n",
      "Epoch 47/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1166 - accuracy: 0.9617 - val_loss: 0.6762 - val_accuracy: 0.8459\n",
      "Epoch 48/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1109 - accuracy: 0.9637 - val_loss: 0.6782 - val_accuracy: 0.8492\n",
      "Epoch 49/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1116 - accuracy: 0.9636 - val_loss: 0.7078 - val_accuracy: 0.8458\n",
      "Epoch 50/75\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.1081 - accuracy: 0.9642 - val_loss: 0.7364 - val_accuracy: 0.8410\n",
      "Epoch 51/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1140 - accuracy: 0.9623 - val_loss: 0.7533 - val_accuracy: 0.8407\n",
      "Epoch 52/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1074 - accuracy: 0.9635 - val_loss: 0.6814 - val_accuracy: 0.8518\n",
      "Epoch 53/75\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1064 - accuracy: 0.9643 - val_loss: 0.6881 - val_accuracy: 0.8527\n",
      "Epoch 54/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1041 - accuracy: 0.9665 - val_loss: 0.7124 - val_accuracy: 0.8499\n",
      "Epoch 55/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0987 - accuracy: 0.9676 - val_loss: 0.7113 - val_accuracy: 0.8495\n",
      "Epoch 56/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0999 - accuracy: 0.9663 - val_loss: 0.7228 - val_accuracy: 0.8470\n",
      "Epoch 57/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.1009 - accuracy: 0.9677 - val_loss: 0.7817 - val_accuracy: 0.8381\n",
      "Epoch 58/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0949 - accuracy: 0.9693 - val_loss: 0.7218 - val_accuracy: 0.8481\n",
      "Epoch 59/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0956 - accuracy: 0.9687 - val_loss: 0.7338 - val_accuracy: 0.8424\n",
      "Epoch 60/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0946 - accuracy: 0.9698 - val_loss: 0.7387 - val_accuracy: 0.8457\n",
      "Epoch 61/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0900 - accuracy: 0.9709 - val_loss: 0.7569 - val_accuracy: 0.8486\n",
      "Epoch 62/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0931 - accuracy: 0.9692 - val_loss: 0.7665 - val_accuracy: 0.8483\n",
      "Epoch 63/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0847 - accuracy: 0.9731 - val_loss: 0.8008 - val_accuracy: 0.8401\n",
      "Epoch 64/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0918 - accuracy: 0.9696 - val_loss: 0.7199 - val_accuracy: 0.8492\n",
      "Epoch 65/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0826 - accuracy: 0.9729 - val_loss: 0.7401 - val_accuracy: 0.8518\n",
      "Epoch 66/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0831 - accuracy: 0.9736 - val_loss: 0.7702 - val_accuracy: 0.8486\n",
      "Epoch 67/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.7386 - val_accuracy: 0.8477\n",
      "Epoch 68/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0829 - accuracy: 0.9737 - val_loss: 0.7498 - val_accuracy: 0.8470\n",
      "Epoch 69/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0824 - accuracy: 0.9729 - val_loss: 0.7541 - val_accuracy: 0.8478\n",
      "Epoch 70/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0803 - accuracy: 0.9735 - val_loss: 0.7196 - val_accuracy: 0.8499\n",
      "Epoch 71/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0808 - accuracy: 0.9747 - val_loss: 0.7992 - val_accuracy: 0.8365\n",
      "Epoch 72/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0787 - accuracy: 0.9746 - val_loss: 0.7564 - val_accuracy: 0.8423\n",
      "Epoch 73/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.7632 - val_accuracy: 0.8492\n",
      "Epoch 74/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0743 - accuracy: 0.9765 - val_loss: 0.8060 - val_accuracy: 0.8434\n",
      "Epoch 75/75\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 0.0807 - accuracy: 0.9740 - val_loss: 0.8565 - val_accuracy: 0.8369\n",
      "Done...Time consumed in training: 8214.93441081047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Save the model\\nclassifier.save(\"/home/app/Desktop/paper 6/code_CIFAR10/classifier.h5\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "min_pixel_value = 0.0\n",
    "max_pixel_value = 1.0\n",
    "\n",
    "\n",
    "t_consumed=0\n",
    "classifier, t_consumed = CNN.train(train_images, train_labels, epochs, batch_size,\n",
    "                                   min_pixel_value, max_pixel_value, test_images, test_labels)\n",
    "\n",
    "'''# Save the model\n",
    "classifier.save(\"/home/app/Desktop/paper 6/code_CIFAR10/classifier.h5\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.69 84.07 83.69 83.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "acc, prc, rec, f1: 10.77 16.71 10.77 3.79\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 47.23 71.63 47.23 51.73\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.1424 - accuracy: 0.9546\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0544 - accuracy: 0.9803\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0434 - accuracy: 0.9842\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0397 - accuracy: 0.9865\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0343 - accuracy: 0.9874\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0337 - accuracy: 0.9884\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0282 - accuracy: 0.9896\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0273 - accuracy: 0.9902\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0268 - accuracy: 0.9906\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0244 - accuracy: 0.9902\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0237 - accuracy: 0.9914\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0218 - accuracy: 0.9924\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0204 - accuracy: 0.9927\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0218 - accuracy: 0.9921\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0182 - accuracy: 0.9934\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0183 - accuracy: 0.9929\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0194 - accuracy: 0.9929\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0158 - accuracy: 0.9941\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0165 - accuracy: 0.9938\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0138 - accuracy: 0.9953\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0162 - accuracy: 0.9947\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0136 - accuracy: 0.9953\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0133 - accuracy: 0.9948\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0126 - accuracy: 0.9953\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0101 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0109 - accuracy: 0.9959\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0100 - accuracy: 0.9963\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0087 - accuracy: 0.9971\n",
      "NN detection: acc, prc, rec, f1: 98.78 98.78 98.78 98.77\n",
      "The number of attacked immages 1 is: 9981\n",
      "The number of clean images 0 is: 10019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.39 83.81 83.39 83.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 97.55 97.55 97.55 97.55\n",
      "The number of attacked immages 1 is: 10019\n",
      "The number of clean images 0 is: 9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.38 83.79 83.38 83.28\n",
      "DT detection: acc, prc, rec, f1: 95.22 95.23 95.22 95.23\n",
      "The number of attacked immages 1 is: 10000\n",
      "The number of clean images 0 is: 10000\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 97.72 97.74 97.72 97.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9898\n",
      "The number of clean images 0 is: 10102\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 82.34 82.92 82.34 82.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 97.48 97.48 97.48 97.47\n",
      "The number of attacked immages 1 is: 10042\n",
      "The number of clean images 0 is: 9958\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.56 83.08 82.56 82.5\n",
      "XGB detection: acc, prc, rec, f1: 93.95 93.98 93.95 93.95\n",
      "The number of attacked immages 1 is: 10243\n",
      "The number of clean images 0 is: 9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 78.95 81.09 78.95 79.39\n",
      "acc, prc, rec, f1: 83.69 84.07 83.69 83.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "acc, prc, rec, f1: 10.81 16.02 10.81 3.89\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 47.25 71.29 47.25 51.71\n",
      "(10000, 32)\n",
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.1139 - accuracy: 0.9591\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0534 - accuracy: 0.9821\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0425 - accuracy: 0.9847\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0397 - accuracy: 0.9859\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0351 - accuracy: 0.9880\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0327 - accuracy: 0.9891\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0318 - accuracy: 0.9892\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0304 - accuracy: 0.9896\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.0283 - accuracy: 0.9898\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0265 - accuracy: 0.9906\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0256 - accuracy: 0.9913\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0235 - accuracy: 0.9924\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0228 - accuracy: 0.9929\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0224 - accuracy: 0.9926\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0205 - accuracy: 0.9936\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0191 - accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0186 - accuracy: 0.9943\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0182 - accuracy: 0.9945\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0158 - accuracy: 0.9954\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0150 - accuracy: 0.9942\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0156 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0135 - accuracy: 0.9955\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0120 - accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0139 - accuracy: 0.9947\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0150 - accuracy: 0.9954\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0111 - accuracy: 0.9959\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0119 - accuracy: 0.9956\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0090 - accuracy: 0.9973\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0100 - accuracy: 0.9968\n",
      "NN detection: acc, prc, rec, f1: 98.8 98.8 98.8 98.8\n",
      "The number of attacked immages 1 is: 9995\n",
      "The number of clean images 0 is: 10005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.48 83.88 83.48 83.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 97.78 97.78 97.78 97.78\n",
      "The number of attacked immages 1 is: 10024\n",
      "The number of clean images 0 is: 9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.36 83.77 83.36 83.26\n",
      "DT detection: acc, prc, rec, f1: 95.6 95.6 95.6 95.6\n",
      "The number of attacked immages 1 is: 9999\n",
      "The number of clean images 0 is: 10001\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.18 83.63 83.18 83.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 98.05 98.05 98.05 98.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9922\n",
      "The number of clean images 0 is: 10078\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 82.51 83.05 82.51 82.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 97.58 97.58 97.58 97.58\n",
      "The number of attacked immages 1 is: 10060\n",
      "The number of clean images 0 is: 9940\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.42 82.97 82.42 82.37\n",
      "XGB detection: acc, prc, rec, f1: 93.35 93.38 93.35 93.35\n",
      "The number of attacked immages 1 is: 10322\n",
      "The number of clean images 0 is: 9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 78.82 80.99 78.82 79.3\n",
      "acc, prc, rec, f1: 83.69 84.07 83.69 83.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "acc, prc, rec, f1: 10.78 13.55 10.78 3.9\n",
      "(10000, 32)\n",
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n",
      "(20000, 32, 32, 3) (20000, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(35, 55, 5):\n",
    "    eps_FSGM= (i/100)\n",
    "    #Evaluate the model\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, test_images, test_labels)\n",
    "\n",
    "    #write the results\n",
    "    import Writer\n",
    "    results =\"===========\\n\" +  dataset + \"-Regular:\\n acc, prc, rec, f1, epochs, batch size, time: acc, prc, rec, f1\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(epochs)+ \",\" + str(batch_size) + \",\" + str(int(t_consumed)) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "    #==================================\n",
    "    \n",
    "    # Extract the features for the regular images\n",
    "    from tensorflow.keras import models\n",
    "\n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_regular = model_output.predict(test_images)\n",
    "    print(Features_regular.shape)   \n",
    "    #==================================\n",
    "\n",
    "    # Generate adversarial examples using the FastGradientMethod attack\n",
    "    from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent #white-box\n",
    "    from art.attacks.evasion import ZooAttack, SquareAttack, BoundaryAttack #black-box\n",
    "\n",
    "\n",
    "    # Initialize the attack\n",
    "    attack = None\n",
    "\n",
    "    # Select the attack\n",
    "    if attack_type == \"FGSM\":\n",
    "        attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "    if attack_type == \"BIM\":\n",
    "        attack = BasicIterativeMethod(estimator=classifier, eps=eps_FSGM)\n",
    "    elif attack_type == \"PGD\":\n",
    "        attack = ProjectedGradientDescent(estimator=classifier, eps=eps_FSGM)\n",
    "    elif attack_type == \"SA\":\n",
    "        attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "    elif attack_type == \"ZA\":\n",
    "        attack = ZooAttack(classifier=classifier, max_iter=2, learning_rate=eps_FSGM)\n",
    "\n",
    "    adv_images = attack.generate(test_images)\n",
    "    #=============================================\n",
    "    \n",
    "    # Evaluate the model on the adversarial test set images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, adv_images, test_labels)\n",
    "\n",
    "    #write the results\n",
    "    results =dataset + \"-Adversarial:\\n acc, prc, rec, f1, epochs, attack_type, eps_FSGM\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + attack_type + \",\" + str(eps_FSGM) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "    #=============================================\n",
    "\n",
    "    # Extract the features for the adversarial images\n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_adversarial = model_output.predict(adv_images)\n",
    "    print(Features_adversarial.shape)\n",
    "    #=============================================\n",
    "\n",
    "    # merge regular and feature test images\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    #merge data features of regular and adversarial images\n",
    "    reg_adv_images = np.concatenate((Features_regular, Features_adversarial), axis=0)\n",
    "\n",
    "    # generate labels for regular and adversarial, and merge them\n",
    "\n",
    "    label_reg = np.zeros((10000, 1))\n",
    "    label_adv = np.ones((10000, 1))\n",
    "    reg_adv_labels=np.concatenate((label_reg, label_adv), axis=0)\n",
    "\n",
    "    print(\"data details: \", reg_adv_images.shape, \" , labels: \", reg_adv_labels.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reg_adv_images, reg_adv_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "    #fractin to use a part of the merged regular and adversarial images\n",
    "    fraction=1\n",
    "    #reduce the length because the memory is out\n",
    "    X_train=X_train[:int(X_train.shape[0]/fraction)]\n",
    "    X_test=X_test[:(int(X_test.shape[0]/fraction))]\n",
    "    y_train=y_train[:(int(y_train.shape[0]/fraction))]\n",
    "    y_test=y_test[:(int(y_test.shape[0]/fraction))]\n",
    "    X_train, X_test, y_train, y_test\n",
    "    print(\"data after split : X_train, X_test, y_train, y_test\\n\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    # integrate the adversarial detector model to CNN to exclude adversarial images or outlier images.\n",
    "\n",
    "    size_advs=10000\n",
    "    test_reg_adv_images=np.concatenate((test_images,adv_images[:size_advs]), axis=0)\n",
    "    test_reg_adv_labels=np.concatenate((test_labels,test_labels[:size_advs]), axis=0)\n",
    "    print(test_reg_adv_images.shape, test_reg_adv_labels.shape)\n",
    "\n",
    "    # Shuffle the data\n",
    "    indices = np.arange(len(test_reg_adv_images))\n",
    "    np.random.shuffle(indices)\n",
    "    test_reg_adv_images= test_reg_adv_images[indices]\n",
    "    test_reg_adv_labels = test_reg_adv_labels[indices]\n",
    "\n",
    "    # Evaluate the model after integrate regular and adversarial images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, test_reg_adv_images, test_reg_adv_labels)\n",
    "    results =dataset + \"-Regular+Adversarial:\\n acc, prc, rec, f1\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) +\"\\n\" \n",
    "    Writer.write_results(results, path)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    # Extract features \n",
    "    model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "    Features_adv_reg = model_output.predict(test_reg_adv_images)\n",
    "    print(Features_adversarial.shape)\n",
    "    #=============================================\n",
    "\n",
    "    #to ensure that the size of regular and adversarial image size are the same to do fair evaluation\n",
    "    def make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels):\n",
    "        diff=int(np.absolute(clean_images.shape[0] - attacked_images.shape[0])/2)\n",
    "        size=int((clean_images.shape[0]+attacked_images.shape[0])/2)\n",
    "        temp_clean_images=np.ones((size,32,32,3))\n",
    "        temp_attacked_images=np.ones((size,32,32,3))\n",
    "\n",
    "        temp_clean_labels=np.ones((size,1))\n",
    "        temp_attacked_labels=np.ones((size,1))\n",
    "\n",
    "        if(clean_images.shape[0]>attacked_images.shape[0]):\n",
    "            temp_clean_images=clean_images[:size]\n",
    "            temp_clean_labels=clean_labels[:size]\n",
    "\n",
    "            temp_attacked_images=np.concatenate((attacked_images,clean_images[-diff:]), axis=0)\n",
    "            temp_attacked_labels=np.concatenate((temp_attacked_labels,clean_labels[-diff:]), axis=0)\n",
    "\n",
    "        elif(clean_images.shape[0]<attacked_images.shape[0]):\n",
    "            temp_attacked_images=attacked_images[:size]\n",
    "            temp_attacked_labels=attacked_labels[:size]\n",
    "\n",
    "            temp_clean_images=np.concatenate((clean_images,attacked_images[-diff:]), axis=0)\n",
    "            temp_clean_labels=np.concatenate((clean_labels,attacked_labels[-diff:]), axis=0)\n",
    "\n",
    "        clean_images=temp_clean_images\n",
    "        clean_labels=temp_clean_labels\n",
    "\n",
    "        attacked_images=temp_attacked_images\n",
    "        attacked_labels=temp_attacked_labels\n",
    "\n",
    "        #print(\"clean_images.shape, attacked_images.shape\", clean_images.shape, attacked_images.shape)\n",
    "        #print(\"clean_labels.shape, attacked_labels.shape\", clean_labels.shape, attacked_labels.shape)\n",
    "\n",
    "        return clean_images,clean_labels, attacked_images, attacked_labels\n",
    "\n",
    "    #Exclude adversarial images from testing and use only the regular images\n",
    "\n",
    "    def retrurn_clean_images(adv_images_pred_binary):\n",
    "\n",
    "        # Count the number of times 1 appears in the array\n",
    "        number_of_1s = np.count_nonzero(adv_images_pred_binary == 1)\n",
    "        # Count the number of times 0 appears in the array\n",
    "        number_of_0s = np.count_nonzero(adv_images_pred_binary == 0)\n",
    "        print(\"The number of attacked immages 1 is:\", number_of_1s)\n",
    "        print(\"The number of clean images 0 is:\", number_of_0s)\n",
    "\n",
    "        #Exclude adversarial images from testing and use only the regular images\n",
    "        # Create a boolean mask use only the clean images\n",
    "        mask_clean = np.where(adv_images_pred_binary == 0)[0]\n",
    "        mask_adv = np.where(adv_images_pred_binary == 1)[0]\n",
    "\n",
    "        # Exclude adversarial images\n",
    "        #clean images\n",
    "        clean_images = test_reg_adv_images[mask_clean]\n",
    "        clean_labels = test_reg_adv_labels[mask_clean]\n",
    "        #Adversarial images,attacked images\n",
    "        attacked_images = test_reg_adv_images[mask_adv]\n",
    "        attacked_labels = test_reg_adv_labels[mask_adv]\n",
    "\n",
    "        clean_images,clean_labels, attacked_images, attacked_labels = make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels)\n",
    "\n",
    "        print(\"clean_images:\", clean_images.shape)\n",
    "        print(\"clean_labels:\", clean_labels.shape)\n",
    "\n",
    "        return clean_images, clean_labels\n",
    "\n",
    "\n",
    "    def eval_model_after_exclude_adv_image(model_name, new_test_clean_images, new_test_clean_labels, t_consumed):# Evaluate the model after excluding the adversarial images\n",
    "        acc, prc, rec, f1 = CNN.test(classifier, new_test_clean_images, new_test_clean_labels)\n",
    "        results =model_name + \":\\n acc, prc, rec, f1, time_detection\\n\"\n",
    "        results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(int(t_consumed)) + \"\\n\" \n",
    "        Writer.write_results(results, path)\n",
    "    #=============================================\n",
    "\n",
    "    #Evaluate the mosdel after inegrate NN as outlier detection to exclude Adversarial images\n",
    "    import ML_Classifiers as MLC\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.NN(X_train, X_test, y_train, y_test,eps_FSGM, attack_type, Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+NN_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate RF as outlier detection to exclude Adversarial images\n",
    "    import ML_Classifiers as MLC\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.Random_Forest(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+RF_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate DT as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "    adv_images_pred_binary= MLC.DT(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+DT_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate KNN as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "    adv_images_pred_binary= MLC.KNN(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+KNN_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate GBM as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.GBM(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+GBM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #=============================================\n",
    "\n",
    "    ##Evaluate the mosdel after inegrate XGB as outlier detection to exclude Adversarial images\n",
    "    t_str=time.time()\n",
    "\n",
    "    adv_images_pred_binary= MLC.XGB(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "\n",
    "    new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "    t_consumed=time.time()-t_str\n",
    "    eval_model_after_exclude_adv_image(\"CNN+XGB_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "    #============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 83.69 84.07 83.69 83.58\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "acc, prc, rec, f1 = CNN.test(classifier, test_images, test_labels)\n",
    "\n",
    "#write the results\n",
    "import Writer\n",
    "results =\"===========\\n\" +  dataset + \"-Regular:\\n acc, prc, rec, f1, epochs, batch size, time: acc, prc, rec, f1\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(epochs)+ \",\" + str(batch_size) + \",\" + str(int(t_consumed)) +\"\\n\" \n",
    "Writer.write_results(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features for the regular images\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "Features_regular = model_output.predict(test_images)\n",
    "print(Features_regular.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial examples using the FastGradientMethod attack\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent #white-box\n",
    "from art.attacks.evasion import ZooAttack, SquareAttack, BoundaryAttack #black-box\n",
    "\n",
    "\n",
    "# Initialize the attack\n",
    "attack = None\n",
    "\n",
    "# Select the attack\n",
    "if attack_type == \"FGSM\":\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "if attack_type == \"BIM\":\n",
    "    attack = BasicIterativeMethod(estimator=classifier, eps=eps_FSGM)\n",
    "elif attack_type == \"PGD\":\n",
    "    attack = ProjectedGradientDescent(estimator=classifier, eps=eps_FSGM)\n",
    "elif attack_type == \"SA\":\n",
    "    attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "elif attack_type == \"ZA\":\n",
    "    attack = ZooAttack(classifier=classifier, max_iter=2, learning_rate=eps_FSGM)\n",
    "\n",
    "\n",
    "\n",
    "adv_images = attack.generate(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 10.8 18.68 10.8 3.83\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the adversarial test set images\n",
    "acc, prc, rec, f1 = CNN.test(classifier, adv_images, test_labels)\n",
    "\n",
    "#write the results\n",
    "results =dataset + \"-Adversarial:\\n acc, prc, rec, f1, epochs, attack_type, eps_FSGM\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + attack_type + \",\" + str(eps_FSGM) +\"\\n\" \n",
    "Writer.write_results(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features for the adversarial images\n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "Features_adversarial = model_output.predict(adv_images)\n",
    "print(Features_adversarial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data details:  (20000, 32)  , labels:  (20000, 1)\n",
      "data after split : X_train, X_test, y_train, y_test\n",
      " (16000, 32) (4000, 32) (16000, 1) (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "# merge regular and feature test images\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#merge data features of regular and adversarial images\n",
    "reg_adv_images = np.concatenate((Features_regular, Features_adversarial), axis=0)\n",
    "\n",
    "# generate labels for regular and adversarial, and merge them\n",
    "\n",
    "label_reg = np.zeros((10000, 1))\n",
    "label_adv = np.ones((10000, 1))\n",
    "reg_adv_labels=np.concatenate((label_reg, label_adv), axis=0)\n",
    "\n",
    "print(\"data details: \", reg_adv_images.shape, \" , labels: \", reg_adv_labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reg_adv_images, reg_adv_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "#fractin to use a part of the merged regular and adversarial images\n",
    "fraction=1\n",
    "#reduce the length because the memory is out\n",
    "X_train=X_train[:int(X_train.shape[0]/fraction)]\n",
    "X_test=X_test[:(int(X_test.shape[0]/fraction))]\n",
    "y_train=y_train[:(int(y_train.shape[0]/fraction))]\n",
    "y_test=y_test[:(int(y_test.shape[0]/fraction))]\n",
    "X_train, X_test, y_train, y_test\n",
    "print(\"data after split : X_train, X_test, y_train, y_test\\n\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import ML_Classifiers as MLC\\n\\nRF_Pred= MLC.Random_Forest(X_train, X_test, y_train, y_test)\\nDT_Pred= MLC.DT(X_train, X_test, y_train, y_test)\\nKNN_Pred= MLC.KNN(X_train, X_test, y_train, y_test)\\nXGB_Pred= MLC.XGB(X_train, X_test, y_train, y_test)\\nNN_Pred= MLC.NN(X_train, X_test, y_train, y_test)\\nNN_Pred= MLC.GBM(X_train, X_test, y_train, y_test)'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import ML_Classifiers as MLC\n",
    "\n",
    "RF_Pred= MLC.Random_Forest(X_train, X_test, y_train, y_test)\n",
    "DT_Pred= MLC.DT(X_train, X_test, y_train, y_test)\n",
    "KNN_Pred= MLC.KNN(X_train, X_test, y_train, y_test)\n",
    "XGB_Pred= MLC.XGB(X_train, X_test, y_train, y_test)\n",
    "NN_Pred= MLC.NN(X_train, X_test, y_train, y_test)\n",
    "NN_Pred= MLC.GBM(X_train, X_test, y_train, y_test)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3) (20000, 1)\n",
      "acc, prc, rec, f1: 47.24 72.07 47.24 51.81\n"
     ]
    }
   ],
   "source": [
    "# integrate the adversarial detector model to CNN to exclude adversarial images or outlier images.\n",
    "\n",
    "size_advs=10000\n",
    "test_reg_adv_images=np.concatenate((test_images,adv_images[:size_advs]), axis=0)\n",
    "test_reg_adv_labels=np.concatenate((test_labels,test_labels[:size_advs]), axis=0)\n",
    "print(test_reg_adv_images.shape, test_reg_adv_labels.shape)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(len(test_reg_adv_images))\n",
    "np.random.shuffle(indices)\n",
    "test_reg_adv_images= test_reg_adv_images[indices]\n",
    "test_reg_adv_labels = test_reg_adv_labels[indices]\n",
    "\n",
    "# Evaluate the model after integrate regular and adversarial images\n",
    "acc, prc, rec, f1 = CNN.test(classifier, test_reg_adv_images, test_reg_adv_labels)\n",
    "results =dataset + \"-Regular+Adversarial:\\n acc, prc, rec, f1\\n\"\n",
    "results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) +\"\\n\" \n",
    "Writer.write_results(results, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract features \n",
    "model_output = models.Model(inputs=classifier._model.input, outputs=classifier._model.get_layer('dense_features').output)\n",
    "Features_adv_reg = model_output.predict(test_reg_adv_images)\n",
    "print(Features_adversarial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ensure that the size of regular and adversarial image size are the same to do fair evaluation\n",
    "def make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels):\n",
    "    diff=int(np.absolute(clean_images.shape[0] - attacked_images.shape[0])/2)\n",
    "    size=int((clean_images.shape[0]+attacked_images.shape[0])/2)\n",
    "    temp_clean_images=np.ones((size,32,32,3))\n",
    "    temp_attacked_images=np.ones((size,32,32,3))\n",
    "\n",
    "    temp_clean_labels=np.ones((size,1))\n",
    "    temp_attacked_labels=np.ones((size,1))\n",
    "    \n",
    "    if(clean_images.shape[0]>attacked_images.shape[0]):\n",
    "        temp_clean_images=clean_images[:size]\n",
    "        temp_clean_labels=clean_labels[:size]\n",
    "        \n",
    "        temp_attacked_images=np.concatenate((attacked_images,clean_images[-diff:]), axis=0)\n",
    "        temp_attacked_labels=np.concatenate((temp_attacked_labels,clean_labels[-diff:]), axis=0)\n",
    "        \n",
    "    elif(clean_images.shape[0]<attacked_images.shape[0]):\n",
    "        temp_attacked_images=attacked_images[:size]\n",
    "        temp_attacked_labels=attacked_labels[:size]\n",
    "\n",
    "        temp_clean_images=np.concatenate((clean_images,attacked_images[-diff:]), axis=0)\n",
    "        temp_clean_labels=np.concatenate((clean_labels,attacked_labels[-diff:]), axis=0)\n",
    "\n",
    "    clean_images=temp_clean_images\n",
    "    clean_labels=temp_clean_labels\n",
    "    \n",
    "    attacked_images=temp_attacked_images\n",
    "    attacked_labels=temp_attacked_labels\n",
    "    \n",
    "    #print(\"clean_images.shape, attacked_images.shape\", clean_images.shape, attacked_images.shape)\n",
    "    #print(\"clean_labels.shape, attacked_labels.shape\", clean_labels.shape, attacked_labels.shape)\n",
    "    \n",
    "    return clean_images,clean_labels, attacked_images, attacked_labels\n",
    "\n",
    "#Exclude adversarial images from testing and use only the regular images\n",
    "\n",
    "def retrurn_clean_images(adv_images_pred_binary):\n",
    "    \n",
    "    # Count the number of times 1 appears in the array\n",
    "    number_of_1s = np.count_nonzero(adv_images_pred_binary == 1)\n",
    "    # Count the number of times 0 appears in the array\n",
    "    number_of_0s = np.count_nonzero(adv_images_pred_binary == 0)\n",
    "    print(\"The number of attacked immages 1 is:\", number_of_1s)\n",
    "    print(\"The number of clean images 0 is:\", number_of_0s)\n",
    "\n",
    "    #Exclude adversarial images from testing and use only the regular images\n",
    "    # Create a boolean mask use only the clean images\n",
    "    mask_clean = np.where(adv_images_pred_binary == 0)[0]\n",
    "    mask_adv = np.where(adv_images_pred_binary == 1)[0]\n",
    "\n",
    "    # Exclude adversarial images\n",
    "    #clean images\n",
    "    clean_images = test_reg_adv_images[mask_clean]\n",
    "    clean_labels = test_reg_adv_labels[mask_clean]\n",
    "    #Adversarial images,attacked images\n",
    "    attacked_images = test_reg_adv_images[mask_adv]\n",
    "    attacked_labels = test_reg_adv_labels[mask_adv]\n",
    "    \n",
    "    clean_images,clean_labels, attacked_images, attacked_labels = make_size_fit(clean_images,clean_labels, attacked_images, attacked_labels)\n",
    "    \n",
    "    print(\"clean_images:\", clean_images.shape)\n",
    "    print(\"clean_labels:\", clean_labels.shape)\n",
    "    \n",
    "    return clean_images, clean_labels\n",
    "\n",
    "\n",
    "def eval_model_after_exclude_adv_image(model_name, new_test_clean_images, new_test_clean_labels, t_consumed):# Evaluate the model after excluding the adversarial images\n",
    "    acc, prc, rec, f1 = CNN.test(classifier, new_test_clean_images, new_test_clean_labels)\n",
    "    results =model_name + \":\\n acc, prc, rec, f1, time_detection\\n\"\n",
    "    results +=str(acc) + \",\" + str(prc) + \",\" + str(rec)+ \",\" + str(f1) + \",\" + str(int(t_consumed)) + \"\\n\" \n",
    "    Writer.write_results(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.1291 - accuracy: 0.9564\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0611 - accuracy: 0.9785\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0494 - accuracy: 0.9823\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0427 - accuracy: 0.9838\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0413 - accuracy: 0.9855\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0362 - accuracy: 0.9864\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0361 - accuracy: 0.9880\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0331 - accuracy: 0.9881\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0333 - accuracy: 0.9890\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0305 - accuracy: 0.9886\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0304 - accuracy: 0.9894\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0282 - accuracy: 0.9901\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0273 - accuracy: 0.9905\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0287 - accuracy: 0.9902\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0247 - accuracy: 0.9914\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0244 - accuracy: 0.9916\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0246 - accuracy: 0.9915\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0257 - accuracy: 0.9916\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0233 - accuracy: 0.9914\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0225 - accuracy: 0.9926\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0205 - accuracy: 0.9933\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0205 - accuracy: 0.9931\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0203 - accuracy: 0.9932\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0182 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0180 - accuracy: 0.9934\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0195 - accuracy: 0.9934\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0189 - accuracy: 0.9927\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0176 - accuracy: 0.9939\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0170 - accuracy: 0.9941\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0153 - accuracy: 0.9946\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0147 - accuracy: 0.9949\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0156 - accuracy: 0.9944\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0130 - accuracy: 0.9951\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0138 - accuracy: 0.9951\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0131 - accuracy: 0.9954\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0118 - accuracy: 0.9959\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 0s 18us/sample - loss: 0.0111 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 0s 19us/sample - loss: 0.0131 - accuracy: 0.9953\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 0s 17us/sample - loss: 0.0108 - accuracy: 0.9963\n",
      "NN detection: acc, prc, rec, f1: 98.6 98.6 98.6 98.6\n",
      "The number of attacked immages 1 is: 9960\n",
      "The number of clean images 0 is: 10040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.31 83.76 83.31 83.21\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the mosdel after inegrate NN as outlier detection to exclude Adversarial images\n",
    "import ML_Classifiers as MLC\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.NN(X_train, X_test, y_train, y_test,eps_FSGM, attack_type, Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+NN_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF detection: acc, prc, rec, f1: 97.68 97.68 97.68 97.68\n",
      "The number of attacked immages 1 is: 10012\n",
      "The number of clean images 0 is: 9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:39: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 83.41 83.82 83.41 83.31\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate RF as outlier detection to exclude Adversarial images\n",
    "import ML_Classifiers as MLC\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.Random_Forest(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+RF_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT detection: acc, prc, rec, f1: 95.22 95.23 95.22 95.23\n",
      "The number of attacked immages 1 is: 10016\n",
      "The number of clean images 0 is: 9984\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.99 83.51 82.99 82.92\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate DT as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "adv_images_pred_binary= MLC.DT(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+DT_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN detection: acc, prc, rec, f1: 97.9 97.91 97.9 97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attacked immages 1 is: 9899\n",
      "The number of clean images 0 is: 10101\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n",
      "acc, prc, rec, f1: 82.33 82.99 82.33 82.28\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate KNN as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "adv_images_pred_binary= MLC.KNN(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+KNN_outlier_detection\", new_test_clean_images, new_test_clean_labels,t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM detection: acc, prc, rec, f1: 97.3 97.3 97.3 97.3\n",
      "The number of attacked immages 1 is: 10040\n",
      "The number of clean images 0 is: 9960\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:200: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 82.43 83.06 82.43 82.39\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate GBM as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.GBM(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+GBM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB detection: acc, prc, rec, f1: 93.22 93.24 93.22 93.23\n",
      "The number of attacked immages 1 is: 10171\n",
      "The number of clean images 0 is: 9829\n",
      "clean_images: (10000, 32, 32, 3)\n",
      "clean_labels: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/Desktop/paper 6/code_CIFAR10/ML_Classifiers.py:161: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(adv_reg_images!=\"\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, prc, rec, f1: 78.47 81.02 78.47 79.04\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the mosdel after inegrate XGB as outlier detection to exclude Adversarial images\n",
    "t_str=time.time()\n",
    "\n",
    "adv_images_pred_binary= MLC.XGB(X_train, X_test, y_train, y_test,Features_adv_reg)\n",
    "\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+XGB_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##Evaluate the mosdel after inegrate FAM as outlier detection to exclude Adversarial images\\nimport FAM \\n\\nt_str=time.time()\\nArtMap=FAM.train(X_train[:5000], y_train[:5000])\\n\\nadv_images_pred_binary = FAM.test(X_test[:1000], y_test[:1000], ArtMap, Features_adv_reg)\\n\\nadv_images_pred_binary=np.array(adv_images_pred_binary)\\nnew_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\\n\\nt_consumed=time.time()-t_str\\neval_model_after_exclude_adv_image(\"CNN+FAM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''##Evaluate the mosdel after inegrate FAM as outlier detection to exclude Adversarial images\n",
    "import FAM \n",
    "\n",
    "t_str=time.time()\n",
    "ArtMap=FAM.train(X_train[:5000], y_train[:5000])\n",
    "\n",
    "adv_images_pred_binary = FAM.test(X_test[:1000], y_test[:1000], ArtMap, Features_adv_reg)\n",
    "\n",
    "adv_images_pred_binary=np.array(adv_images_pred_binary)\n",
    "new_test_clean_images, new_test_clean_labels = retrurn_clean_images(adv_images_pred_binary)\n",
    "\n",
    "t_consumed=time.time()-t_str\n",
    "eval_model_after_exclude_adv_image(\"CNN+FAM_outlier_detection\", new_test_clean_images, new_test_clean_labels, t_consumed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom art.attacks.evasion import ZooAttack\\nattack = ZooAttack(classifier=classifier)\\n\\n\\n\\n#attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\\nadv_images = attack.generate(test_images)\\n\\nattack = SquareAttack(estimator=classifier,eps=eps_FSGM)\\nadv_images = attack.generate(test_images)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from art.attacks.evasion import ZooAttack\n",
    "attack = ZooAttack(classifier=classifier)\n",
    "\n",
    "\n",
    "\n",
    "#attack = FastGradientMethod(estimator=classifier, eps=eps_FSGM)\n",
    "adv_images = attack.generate(test_images)\n",
    "\n",
    "attack = SquareAttack(estimator=classifier,eps=eps_FSGM)\n",
    "adv_images = attack.generate(test_images)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "0.4\n",
      "0.45\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "    print (eps_FSGM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit80eb8a0716134baf971013e72a8cbe27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
